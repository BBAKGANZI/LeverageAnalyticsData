{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02.신경망적용.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9oIXawoCnM5"
      },
      "source": [
        "# 신경망 적용해보기\n",
        "## 보스턴 주택 가격 예측\n",
        " - 데이터 설명\n",
        "  - 13개의 특성, 레이블은 주택 가격의 중간가격(＄1000단위)\n",
        "  - 특성마다 값을 나타내는 방법이 다르므로 표준화(Standardization)를 수행함\n",
        "    - ex) 범죄율 0 ~ 1, 방 개수 3 ~ 9등\n",
        "  - 표준화는 데이터의 평균을 빼고, 표준편차로 나눠줍니다 -> Z-Normalization 표준정규분포 참고\n",
        "    - 다른 머신러닝 전처리 방법에도 사용됨!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkEMGrfFD3-T"
      },
      "source": [
        "### 보스턴 주택가격 데이터셋 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkcnqMPa9Sy5",
        "outputId": "51a05614-f49b-4005-81c0-ba5e27f25ecb"
      },
      "source": [
        "from tensorflow.keras.datasets.boston_housing import load_data\n",
        "\n",
        "# 데이터를 다운받습니다.\n",
        "(x_train, y_train), (x_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                 test_split=0.2,\n",
        "                                                 seed=777)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "65536/57026 [==================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsrDfsNiD9Wc"
      },
      "source": [
        "### 데이터 형태 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpGkjGA1AhIq",
        "outputId": "3ef205fa-ac97-4de1-94b0-a0b46487aa8c"
      },
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(404, 13) (404,)\n",
            "(102, 13) (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0Jo9V-dD_r2"
      },
      "source": [
        "### 데이터 전처리 및 검증 데이터셋 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61rSJkoaCF3a"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 데이터 표준화\n",
        "mean = np.mean(x_train, axis = 0)\n",
        "std = np.std(x_train, axis = 0)\n",
        "\n",
        "x_train = (x_train - mean) / std\n",
        "x_test = (x_test - mean) / std\n",
        "\n",
        "# 훈련 데이터셋과 검증 데이터셋으로 나눕니다.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, \n",
        "                                                  test_size = 0.33, \n",
        "                                                  random_state = 777)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmi09UzHEC2l"
      },
      "source": [
        "### 모델 구성하기\n",
        " - 모델의 마지막 Dense층에서 별도의 활성화 함수를 사용하지 않음\n",
        "  - 인자를 설정하지 않은 경우, default는 'linear'로 설정\n",
        " - 손실 함수는 회귀문제에서 주로 사용되는 평균 제곱 오차(MSE:Mean Squared Error)를 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1VgpWr8AifW"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 입력 데이터의 형태를 꼭 명시해야 합니다.\n",
        "# 13차원의 데이터를 입력으로 받고, 64개의 출력을 가지는 첫 번째 Dense 층\n",
        "model.add(Dense(10, activation = 'relu', input_shape = (13, )))     # x값 숫자 안맞으면 error # 첫번째 층은 activation 생략하기도 함.\n",
        "model.add(Dense(5, activation = 'relu')) # 32개의 출력을 가지는 Dense 층   # 이층은 사용자 마음\n",
        "# model.add(dropout(0.25))  # w25% 없애겠다\n",
        "# model.add 를 몇개를 더 하든 상관없음 단, activation은 relu를 함.\n",
        "model.add(Dense(1)) # 하나의 값을 출력합니다.       -> 최종 출력층, 선형회귀는 1개, 활성화함수는 생략가능\n",
        "\n",
        "#model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae','acc'], )  # 'acc'는 성공률\n",
        "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['acc'], )"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GFMjPVCH5ew",
        "outputId": "0e0b1379-63f5-42b4-b396-386992fbf161"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 3ms/step - loss: 639.2335 - mae: 23.5039\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[639.2335205078125, 23.50394058227539]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NJhaQWNBuXq",
        "outputId": "fa8aa7be-5f8f-4103-815c-bc29e8084ca7"
      },
      "source": [
        "model.summary()\n",
        "# Param 구하는 공식 ==> dense수 * input구 + dense수\n",
        "# 1번층 Dense(10)는 13개의 w값과 1개의 b를 갖는 총 14개의 param이 10개 있음.-> 14*10=140개의 param이 나옴(최종 dense만큼 node가 나옴)\n",
        "    # => 10*13+10\n",
        "# 2번층 Dense(5)는 1번층 dense의 10개의 노드가 input값이 됨, 10개의 w와 1개의 b가 있음, 한세트는 11개임 * 5 = 55개의 param\n",
        "    # => 5*10+5\n",
        "# 3번층 Dense(1)은 2번층의 dense 5개가 input임 (5개의 w, 1개의 b=>총 6개)\n",
        "    # => 1*5+1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                140       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 55        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 201\n",
            "Trainable params: 201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_vsbbbzJCVD"
      },
      "source": [
        "# 모델의 가중치값 표시\n",
        "[\n",
        "layer1 => dense w 13개[dense1번 w 13개], [dense2번 w 13개].......[dense10번 w13개]\n",
        "layer2 => dense 5 w 10개[dense 1번 w1개].....[dense 5번 w1개]\n",
        "layer3 => dense 1 w 5개[dense1번 w 5개]\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_HBMZ0fKOI0",
        "outputId": "f641ce97-71cc-4021-f434-3181ee783749"
      },
      "source": [
        "model.get_weights()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.4487946 ,  0.17028183,  0.17046362, -0.13386115,  0.39447802,\n",
              "         -0.19464755,  0.08181775,  0.28031588, -0.45281252, -0.03022009],\n",
              "        [-0.28008145,  0.13809937,  0.05273902, -0.23516554,  0.31342775,\n",
              "          0.02867663, -0.179432  , -0.3332322 ,  0.486453  , -0.1683667 ],\n",
              "        [-0.22403705, -0.19973257,  0.24138242, -0.3476225 ,  0.12496883,\n",
              "         -0.29258877, -0.07052398, -0.03958458,  0.34765673, -0.33205476],\n",
              "        [ 0.2334137 , -0.04020599, -0.00202048, -0.41706404,  0.2981034 ,\n",
              "         -0.35560316, -0.48512748,  0.25643617, -0.2878131 ,  0.3828718 ],\n",
              "        [ 0.2539354 , -0.02162194, -0.12869775,  0.1474433 , -0.16333285,\n",
              "          0.39730072, -0.1597107 ,  0.25363207,  0.27866656, -0.4489349 ],\n",
              "        [ 0.19163805,  0.27771395,  0.488221  , -0.09125918, -0.36772776,\n",
              "         -0.47068092,  0.32751065,  0.15960634,  0.37759805,  0.284047  ],\n",
              "        [ 0.10921389, -0.0603072 , -0.31067628,  0.44496584,  0.3455354 ,\n",
              "          0.26553237, -0.37032688, -0.3667482 ,  0.2975961 , -0.2779652 ],\n",
              "        [-0.07043096, -0.237497  , -0.14329141,  0.16545045, -0.2978545 ,\n",
              "          0.46420377, -0.12591645, -0.4308276 ,  0.34801865, -0.3585782 ],\n",
              "        [-0.47442654, -0.078284  , -0.08744791, -0.44017124,  0.45924675,\n",
              "          0.25068736,  0.36832774,  0.07861352, -0.24616787,  0.2812131 ],\n",
              "        [ 0.21243513,  0.40955257, -0.0848456 ,  0.39221805,  0.4995026 ,\n",
              "          0.0268572 ,  0.00767344, -0.1941126 , -0.2764788 ,  0.46751666],\n",
              "        [-0.4036473 ,  0.3677371 ,  0.20824474, -0.48321456,  0.47451335,\n",
              "          0.39121366,  0.2206124 , -0.4111042 , -0.02552974, -0.00331992],\n",
              "        [-0.18986395, -0.23110098,  0.49416798, -0.12164962,  0.12188041,\n",
              "          0.46932232,  0.24826872,  0.22182769, -0.18599412,  0.40103847],\n",
              "        [-0.32250834, -0.21526194, -0.22751379,  0.05996418, -0.1278641 ,\n",
              "          0.34073794, -0.31354097, -0.27879846,  0.2070055 ,  0.18529135]],\n",
              "       dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
              " array([[-0.47125787,  0.555039  ,  0.20800805, -0.24460125, -0.11363381],\n",
              "        [ 0.20655912, -0.20496285, -0.4593197 ,  0.4109438 ,  0.34884286],\n",
              "        [-0.1803337 ,  0.09679848,  0.51984805, -0.0990662 ,  0.5096225 ],\n",
              "        [ 0.24394202, -0.02803773,  0.42730242, -0.1841211 ,  0.07203799],\n",
              "        [-0.49610084, -0.34672818,  0.4695446 ,  0.23629504,  0.50270194],\n",
              "        [ 0.35651183,  0.536226  , -0.01169008,  0.12021846,  0.21707517],\n",
              "        [ 0.02920604,  0.43047947,  0.3682683 , -0.4113549 , -0.13004887],\n",
              "        [-0.12075663,  0.44387347,  0.08196658,  0.22574764,  0.09885919],\n",
              "        [-0.35309073,  0.40365273, -0.5348743 , -0.11971992,  0.12912816],\n",
              "        [-0.33154657, -0.6259526 ,  0.62385374,  0.4555903 ,  0.2547601 ]],\n",
              "       dtype=float32),\n",
              " array([0., 0., 0., 0., 0.], dtype=float32),\n",
              " array([[ 0.5308156],\n",
              "        [ 0.3264246],\n",
              "        [-0.9218924],\n",
              "        [ 0.8479433],\n",
              "        [ 0.8750434]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYCdbSl7EbYA"
      },
      "source": [
        "### 학습하고 평가하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYGSNyvLCWZe",
        "outputId": "6ed5b483-1375-4421-f31a-cf5b8f475757"
      },
      "source": [
        "# 오버피팅(가중치가 훈련데이터만 잘 맞는경우)를 확인하는 방법\n",
        "# 오버피팅이 있으면 dense수를 줄이거나, 모델의 add를 줄이거나, epochs를 줄이거나, 모델 add사이에 dropout을 넣거나, 배치를 크게하거나, 러닝레이트값을 크게하거나\n",
        "# 오버피팅의 대한 정답은 없음\n",
        "# w,b 갱신은 훈련데이터하고만 작업함 / 검증이나 테스트데이터는 w,b를 넣어서 계산만 함.\n",
        "\n",
        "# 훈련데이터의 loss값은 줄어드는데 검증데이터의 loss값은 늘어나는 경우\n",
        "history = model.fit(x_train, y_train, \n",
        "                    epochs = 500, # 수치에 따라 그래프 값이 많이 변함\n",
        "                    validation_data = (x_val, y_val)) # 검증데이터는 훈련데이터의 몇%로 하기도 하고, 지금처럼 별도의 데이터를 넣어서 하기도함.\n",
        "                    # 보통 테스트 데이터 많이 넣음"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.6595 - acc: 0.0000e+00 - val_loss: 18.4359 - val_acc: 0.0000e+00\n",
            "Epoch 2/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.6430 - acc: 0.0000e+00 - val_loss: 18.4702 - val_acc: 0.0000e+00\n",
            "Epoch 3/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.6487 - acc: 0.0000e+00 - val_loss: 18.3941 - val_acc: 0.0000e+00\n",
            "Epoch 4/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.6404 - acc: 0.0000e+00 - val_loss: 18.4974 - val_acc: 0.0000e+00\n",
            "Epoch 5/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.6095 - acc: 0.0000e+00 - val_loss: 18.4012 - val_acc: 0.0000e+00\n",
            "Epoch 6/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.6174 - acc: 0.0000e+00 - val_loss: 18.3026 - val_acc: 0.0000e+00\n",
            "Epoch 7/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.6244 - acc: 0.0000e+00 - val_loss: 18.5045 - val_acc: 0.0000e+00\n",
            "Epoch 8/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.5811 - acc: 0.0000e+00 - val_loss: 18.4391 - val_acc: 0.0000e+00\n",
            "Epoch 9/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.6439 - acc: 0.0000e+00 - val_loss: 18.1874 - val_acc: 0.0000e+00\n",
            "Epoch 10/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.5453 - acc: 0.0000e+00 - val_loss: 18.3213 - val_acc: 0.0000e+00\n",
            "Epoch 11/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.5209 - acc: 0.0000e+00 - val_loss: 18.4662 - val_acc: 0.0000e+00\n",
            "Epoch 12/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.5483 - acc: 0.0000e+00 - val_loss: 18.4596 - val_acc: 0.0000e+00\n",
            "Epoch 13/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.4899 - acc: 0.0000e+00 - val_loss: 18.1631 - val_acc: 0.0000e+00\n",
            "Epoch 14/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.4873 - acc: 0.0000e+00 - val_loss: 18.1496 - val_acc: 0.0000e+00\n",
            "Epoch 15/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4791 - acc: 0.0000e+00 - val_loss: 18.1886 - val_acc: 0.0000e+00\n",
            "Epoch 16/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.4828 - acc: 0.0000e+00 - val_loss: 18.1216 - val_acc: 0.0000e+00\n",
            "Epoch 17/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.4815 - acc: 0.0000e+00 - val_loss: 17.9005 - val_acc: 0.0000e+00\n",
            "Epoch 18/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.4904 - acc: 0.0000e+00 - val_loss: 18.1573 - val_acc: 0.0000e+00\n",
            "Epoch 19/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.4782 - acc: 0.0000e+00 - val_loss: 18.1989 - val_acc: 0.0000e+00\n",
            "Epoch 20/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.4152 - acc: 0.0000e+00 - val_loss: 17.8437 - val_acc: 0.0000e+00\n",
            "Epoch 21/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.4213 - acc: 0.0000e+00 - val_loss: 17.8174 - val_acc: 0.0000e+00\n",
            "Epoch 22/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.4167 - acc: 0.0000e+00 - val_loss: 17.8991 - val_acc: 0.0000e+00\n",
            "Epoch 23/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.4127 - acc: 0.0000e+00 - val_loss: 18.0597 - val_acc: 0.0000e+00\n",
            "Epoch 24/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.3775 - acc: 0.0000e+00 - val_loss: 17.9762 - val_acc: 0.0000e+00\n",
            "Epoch 25/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.3719 - acc: 0.0000e+00 - val_loss: 18.0732 - val_acc: 0.0000e+00\n",
            "Epoch 26/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.3408 - acc: 0.0000e+00 - val_loss: 17.8437 - val_acc: 0.0000e+00\n",
            "Epoch 27/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.3647 - acc: 0.0000e+00 - val_loss: 17.7499 - val_acc: 0.0000e+00\n",
            "Epoch 28/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.3315 - acc: 0.0000e+00 - val_loss: 17.9785 - val_acc: 0.0000e+00\n",
            "Epoch 29/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.3149 - acc: 0.0000e+00 - val_loss: 18.0022 - val_acc: 0.0000e+00\n",
            "Epoch 30/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.3277 - acc: 0.0000e+00 - val_loss: 18.1870 - val_acc: 0.0000e+00\n",
            "Epoch 31/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.3005 - acc: 0.0000e+00 - val_loss: 17.9862 - val_acc: 0.0000e+00\n",
            "Epoch 32/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.3151 - acc: 0.0000e+00 - val_loss: 18.0172 - val_acc: 0.0000e+00\n",
            "Epoch 33/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.2759 - acc: 0.0000e+00 - val_loss: 17.8960 - val_acc: 0.0000e+00\n",
            "Epoch 34/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.2587 - acc: 0.0000e+00 - val_loss: 17.9975 - val_acc: 0.0000e+00\n",
            "Epoch 35/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.2656 - acc: 0.0000e+00 - val_loss: 17.9206 - val_acc: 0.0000e+00\n",
            "Epoch 36/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.2359 - acc: 0.0000e+00 - val_loss: 17.8660 - val_acc: 0.0000e+00\n",
            "Epoch 37/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.2452 - acc: 0.0000e+00 - val_loss: 17.8003 - val_acc: 0.0000e+00\n",
            "Epoch 38/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.2202 - acc: 0.0000e+00 - val_loss: 17.7567 - val_acc: 0.0000e+00\n",
            "Epoch 39/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.2205 - acc: 0.0000e+00 - val_loss: 17.9086 - val_acc: 0.0000e+00\n",
            "Epoch 40/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.1993 - acc: 0.0000e+00 - val_loss: 17.9893 - val_acc: 0.0000e+00\n",
            "Epoch 41/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.2041 - acc: 0.0000e+00 - val_loss: 17.9213 - val_acc: 0.0000e+00\n",
            "Epoch 42/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.1934 - acc: 0.0000e+00 - val_loss: 18.0313 - val_acc: 0.0000e+00\n",
            "Epoch 43/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.1821 - acc: 0.0000e+00 - val_loss: 17.8361 - val_acc: 0.0000e+00\n",
            "Epoch 44/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.1712 - acc: 0.0000e+00 - val_loss: 17.8620 - val_acc: 0.0000e+00\n",
            "Epoch 45/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.1507 - acc: 0.0000e+00 - val_loss: 17.7791 - val_acc: 0.0000e+00\n",
            "Epoch 46/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.1370 - acc: 0.0000e+00 - val_loss: 17.7998 - val_acc: 0.0000e+00\n",
            "Epoch 47/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.1468 - acc: 0.0000e+00 - val_loss: 17.5971 - val_acc: 0.0000e+00\n",
            "Epoch 48/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.1250 - acc: 0.0000e+00 - val_loss: 17.6389 - val_acc: 0.0000e+00\n",
            "Epoch 49/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.1108 - acc: 0.0000e+00 - val_loss: 17.6480 - val_acc: 0.0000e+00\n",
            "Epoch 50/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.1195 - acc: 0.0000e+00 - val_loss: 17.7362 - val_acc: 0.0000e+00\n",
            "Epoch 51/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.0982 - acc: 0.0000e+00 - val_loss: 17.6457 - val_acc: 0.0000e+00\n",
            "Epoch 52/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.0953 - acc: 0.0000e+00 - val_loss: 17.6597 - val_acc: 0.0000e+00\n",
            "Epoch 53/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.0549 - acc: 0.0000e+00 - val_loss: 17.7812 - val_acc: 0.0000e+00\n",
            "Epoch 54/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.1034 - acc: 0.0000e+00 - val_loss: 17.7524 - val_acc: 0.0000e+00\n",
            "Epoch 55/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.0787 - acc: 0.0000e+00 - val_loss: 17.5582 - val_acc: 0.0000e+00\n",
            "Epoch 56/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.1227 - acc: 0.0000e+00 - val_loss: 17.4895 - val_acc: 0.0000e+00\n",
            "Epoch 57/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.0459 - acc: 0.0000e+00 - val_loss: 17.4799 - val_acc: 0.0000e+00\n",
            "Epoch 58/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.0313 - acc: 0.0000e+00 - val_loss: 17.5148 - val_acc: 0.0000e+00\n",
            "Epoch 59/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.0168 - acc: 0.0000e+00 - val_loss: 17.5763 - val_acc: 0.0000e+00\n",
            "Epoch 60/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.0169 - acc: 0.0000e+00 - val_loss: 17.4897 - val_acc: 0.0000e+00\n",
            "Epoch 61/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.0035 - acc: 0.0000e+00 - val_loss: 17.4287 - val_acc: 0.0000e+00\n",
            "Epoch 62/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.9973 - acc: 0.0000e+00 - val_loss: 17.5888 - val_acc: 0.0000e+00\n",
            "Epoch 63/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.9869 - acc: 0.0000e+00 - val_loss: 17.5165 - val_acc: 0.0000e+00\n",
            "Epoch 64/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.9774 - acc: 0.0000e+00 - val_loss: 17.4183 - val_acc: 0.0000e+00\n",
            "Epoch 65/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.9673 - acc: 0.0000e+00 - val_loss: 17.3876 - val_acc: 0.0000e+00\n",
            "Epoch 66/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.9835 - acc: 0.0000e+00 - val_loss: 17.5173 - val_acc: 0.0000e+00\n",
            "Epoch 67/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.9633 - acc: 0.0000e+00 - val_loss: 17.4834 - val_acc: 0.0000e+00\n",
            "Epoch 68/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.9366 - acc: 0.0000e+00 - val_loss: 17.3981 - val_acc: 0.0000e+00\n",
            "Epoch 69/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.9649 - acc: 0.0000e+00 - val_loss: 17.2074 - val_acc: 0.0000e+00\n",
            "Epoch 70/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.9095 - acc: 0.0000e+00 - val_loss: 17.3247 - val_acc: 0.0000e+00\n",
            "Epoch 71/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.9102 - acc: 0.0000e+00 - val_loss: 17.3256 - val_acc: 0.0000e+00\n",
            "Epoch 72/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.9027 - acc: 0.0000e+00 - val_loss: 17.2141 - val_acc: 0.0000e+00\n",
            "Epoch 73/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.8929 - acc: 0.0000e+00 - val_loss: 17.1521 - val_acc: 0.0000e+00\n",
            "Epoch 74/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.8807 - acc: 0.0000e+00 - val_loss: 17.3368 - val_acc: 0.0000e+00\n",
            "Epoch 75/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.8971 - acc: 0.0000e+00 - val_loss: 17.4264 - val_acc: 0.0000e+00\n",
            "Epoch 76/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8750 - acc: 0.0000e+00 - val_loss: 17.3652 - val_acc: 0.0000e+00\n",
            "Epoch 77/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8631 - acc: 0.0000e+00 - val_loss: 17.1550 - val_acc: 0.0000e+00\n",
            "Epoch 78/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8572 - acc: 0.0000e+00 - val_loss: 17.0962 - val_acc: 0.0000e+00\n",
            "Epoch 79/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.8563 - acc: 0.0000e+00 - val_loss: 17.2630 - val_acc: 0.0000e+00\n",
            "Epoch 80/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8856 - acc: 0.0000e+00 - val_loss: 17.1931 - val_acc: 0.0000e+00\n",
            "Epoch 81/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8351 - acc: 0.0000e+00 - val_loss: 17.4132 - val_acc: 0.0000e+00\n",
            "Epoch 82/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8330 - acc: 0.0000e+00 - val_loss: 17.4690 - val_acc: 0.0000e+00\n",
            "Epoch 83/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.8388 - acc: 0.0000e+00 - val_loss: 17.2932 - val_acc: 0.0000e+00\n",
            "Epoch 84/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.8187 - acc: 0.0000e+00 - val_loss: 17.2296 - val_acc: 0.0000e+00\n",
            "Epoch 85/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.8223 - acc: 0.0000e+00 - val_loss: 17.1442 - val_acc: 0.0000e+00\n",
            "Epoch 86/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.8193 - acc: 0.0000e+00 - val_loss: 16.9384 - val_acc: 0.0000e+00\n",
            "Epoch 87/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.7883 - acc: 0.0000e+00 - val_loss: 17.0287 - val_acc: 0.0000e+00\n",
            "Epoch 88/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.7682 - acc: 0.0000e+00 - val_loss: 17.0396 - val_acc: 0.0000e+00\n",
            "Epoch 89/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.7615 - acc: 0.0000e+00 - val_loss: 17.1358 - val_acc: 0.0000e+00\n",
            "Epoch 90/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.7648 - acc: 0.0000e+00 - val_loss: 17.0338 - val_acc: 0.0000e+00\n",
            "Epoch 91/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.7845 - acc: 0.0000e+00 - val_loss: 17.1877 - val_acc: 0.0000e+00\n",
            "Epoch 92/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.7749 - acc: 0.0000e+00 - val_loss: 17.0636 - val_acc: 0.0000e+00\n",
            "Epoch 93/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.7819 - acc: 0.0000e+00 - val_loss: 16.9630 - val_acc: 0.0000e+00\n",
            "Epoch 94/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.7803 - acc: 0.0000e+00 - val_loss: 17.0985 - val_acc: 0.0000e+00\n",
            "Epoch 95/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.7610 - acc: 0.0000e+00 - val_loss: 17.0772 - val_acc: 0.0000e+00\n",
            "Epoch 96/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.7209 - acc: 0.0000e+00 - val_loss: 17.0897 - val_acc: 0.0000e+00\n",
            "Epoch 97/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.7369 - acc: 0.0000e+00 - val_loss: 16.8629 - val_acc: 0.0000e+00\n",
            "Epoch 98/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.7046 - acc: 0.0000e+00 - val_loss: 16.8105 - val_acc: 0.0000e+00\n",
            "Epoch 99/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.7056 - acc: 0.0000e+00 - val_loss: 16.8425 - val_acc: 0.0000e+00\n",
            "Epoch 100/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.7314 - acc: 0.0000e+00 - val_loss: 17.0478 - val_acc: 0.0000e+00\n",
            "Epoch 101/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.6899 - acc: 0.0000e+00 - val_loss: 16.7728 - val_acc: 0.0000e+00\n",
            "Epoch 102/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.6742 - acc: 0.0000e+00 - val_loss: 16.7811 - val_acc: 0.0000e+00\n",
            "Epoch 103/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.6743 - acc: 0.0000e+00 - val_loss: 16.7554 - val_acc: 0.0000e+00\n",
            "Epoch 104/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.6609 - acc: 0.0000e+00 - val_loss: 16.7353 - val_acc: 0.0000e+00\n",
            "Epoch 105/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.6581 - acc: 0.0000e+00 - val_loss: 16.9100 - val_acc: 0.0000e+00\n",
            "Epoch 106/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.6538 - acc: 0.0000e+00 - val_loss: 16.8467 - val_acc: 0.0000e+00\n",
            "Epoch 107/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.6699 - acc: 0.0000e+00 - val_loss: 16.7867 - val_acc: 0.0000e+00\n",
            "Epoch 108/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.6433 - acc: 0.0000e+00 - val_loss: 16.7318 - val_acc: 0.0000e+00\n",
            "Epoch 109/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.6323 - acc: 0.0000e+00 - val_loss: 16.9297 - val_acc: 0.0000e+00\n",
            "Epoch 110/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.6064 - acc: 0.0000e+00 - val_loss: 16.9777 - val_acc: 0.0000e+00\n",
            "Epoch 111/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.6072 - acc: 0.0000e+00 - val_loss: 16.8270 - val_acc: 0.0000e+00\n",
            "Epoch 112/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.5994 - acc: 0.0000e+00 - val_loss: 16.7832 - val_acc: 0.0000e+00\n",
            "Epoch 113/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.5757 - acc: 0.0000e+00 - val_loss: 16.7977 - val_acc: 0.0000e+00\n",
            "Epoch 114/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.5818 - acc: 0.0000e+00 - val_loss: 16.8582 - val_acc: 0.0000e+00\n",
            "Epoch 115/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.5739 - acc: 0.0000e+00 - val_loss: 16.8390 - val_acc: 0.0000e+00\n",
            "Epoch 116/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6117 - acc: 0.0000e+00 - val_loss: 16.8885 - val_acc: 0.0000e+00\n",
            "Epoch 117/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.5455 - acc: 0.0000e+00 - val_loss: 16.8730 - val_acc: 0.0000e+00\n",
            "Epoch 118/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.5364 - acc: 0.0000e+00 - val_loss: 16.8523 - val_acc: 0.0000e+00\n",
            "Epoch 119/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.5724 - acc: 0.0000e+00 - val_loss: 16.6794 - val_acc: 0.0000e+00\n",
            "Epoch 120/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.5510 - acc: 0.0000e+00 - val_loss: 16.5588 - val_acc: 0.0000e+00\n",
            "Epoch 121/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.5521 - acc: 0.0000e+00 - val_loss: 16.6815 - val_acc: 0.0000e+00\n",
            "Epoch 122/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.5360 - acc: 0.0000e+00 - val_loss: 16.6490 - val_acc: 0.0000e+00\n",
            "Epoch 123/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.5110 - acc: 0.0000e+00 - val_loss: 16.5708 - val_acc: 0.0000e+00\n",
            "Epoch 124/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.5059 - acc: 0.0000e+00 - val_loss: 16.6880 - val_acc: 0.0000e+00\n",
            "Epoch 125/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.5080 - acc: 0.0000e+00 - val_loss: 16.6182 - val_acc: 0.0000e+00\n",
            "Epoch 126/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.5030 - acc: 0.0000e+00 - val_loss: 16.8157 - val_acc: 0.0000e+00\n",
            "Epoch 127/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.4888 - acc: 0.0000e+00 - val_loss: 16.7909 - val_acc: 0.0000e+00\n",
            "Epoch 128/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.4777 - acc: 0.0000e+00 - val_loss: 16.6410 - val_acc: 0.0000e+00\n",
            "Epoch 129/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.4831 - acc: 0.0000e+00 - val_loss: 16.7148 - val_acc: 0.0000e+00\n",
            "Epoch 130/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4765 - acc: 0.0000e+00 - val_loss: 16.7181 - val_acc: 0.0000e+00\n",
            "Epoch 131/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4637 - acc: 0.0000e+00 - val_loss: 16.7033 - val_acc: 0.0000e+00\n",
            "Epoch 132/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.4491 - acc: 0.0000e+00 - val_loss: 16.5937 - val_acc: 0.0000e+00\n",
            "Epoch 133/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.4470 - acc: 0.0000e+00 - val_loss: 16.3857 - val_acc: 0.0000e+00\n",
            "Epoch 134/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.4837 - acc: 0.0000e+00 - val_loss: 16.3775 - val_acc: 0.0000e+00\n",
            "Epoch 135/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.4409 - acc: 0.0000e+00 - val_loss: 16.5097 - val_acc: 0.0000e+00\n",
            "Epoch 136/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4455 - acc: 0.0000e+00 - val_loss: 16.4536 - val_acc: 0.0000e+00\n",
            "Epoch 137/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4253 - acc: 0.0000e+00 - val_loss: 16.4769 - val_acc: 0.0000e+00\n",
            "Epoch 138/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.4087 - acc: 0.0000e+00 - val_loss: 16.4896 - val_acc: 0.0000e+00\n",
            "Epoch 139/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.4032 - acc: 0.0000e+00 - val_loss: 16.5593 - val_acc: 0.0000e+00\n",
            "Epoch 140/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.4121 - acc: 0.0000e+00 - val_loss: 16.3978 - val_acc: 0.0000e+00\n",
            "Epoch 141/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.4136 - acc: 0.0000e+00 - val_loss: 16.3273 - val_acc: 0.0000e+00\n",
            "Epoch 142/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.3960 - acc: 0.0000e+00 - val_loss: 16.3982 - val_acc: 0.0000e+00\n",
            "Epoch 143/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.3820 - acc: 0.0000e+00 - val_loss: 16.3063 - val_acc: 0.0000e+00\n",
            "Epoch 144/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4043 - acc: 0.0000e+00 - val_loss: 16.4769 - val_acc: 0.0000e+00\n",
            "Epoch 145/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.3678 - acc: 0.0000e+00 - val_loss: 16.3570 - val_acc: 0.0000e+00\n",
            "Epoch 146/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.3628 - acc: 0.0000e+00 - val_loss: 16.4591 - val_acc: 0.0000e+00\n",
            "Epoch 147/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.3964 - acc: 0.0000e+00 - val_loss: 16.2551 - val_acc: 0.0000e+00\n",
            "Epoch 148/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.3569 - acc: 0.0000e+00 - val_loss: 16.3630 - val_acc: 0.0000e+00\n",
            "Epoch 149/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.3518 - acc: 0.0000e+00 - val_loss: 16.4592 - val_acc: 0.0000e+00\n",
            "Epoch 150/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.3503 - acc: 0.0000e+00 - val_loss: 16.5205 - val_acc: 0.0000e+00\n",
            "Epoch 151/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.3368 - acc: 0.0000e+00 - val_loss: 16.3250 - val_acc: 0.0000e+00\n",
            "Epoch 152/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.3327 - acc: 0.0000e+00 - val_loss: 16.2813 - val_acc: 0.0000e+00\n",
            "Epoch 153/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.3239 - acc: 0.0000e+00 - val_loss: 16.2813 - val_acc: 0.0000e+00\n",
            "Epoch 154/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.3068 - acc: 0.0000e+00 - val_loss: 16.3968 - val_acc: 0.0000e+00\n",
            "Epoch 155/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.3211 - acc: 0.0000e+00 - val_loss: 16.2699 - val_acc: 0.0000e+00\n",
            "Epoch 156/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.2949 - acc: 0.0000e+00 - val_loss: 16.4515 - val_acc: 0.0000e+00\n",
            "Epoch 157/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.2994 - acc: 0.0000e+00 - val_loss: 16.5265 - val_acc: 0.0000e+00\n",
            "Epoch 158/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.3190 - acc: 0.0000e+00 - val_loss: 16.4316 - val_acc: 0.0000e+00\n",
            "Epoch 159/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.2750 - acc: 0.0000e+00 - val_loss: 16.3660 - val_acc: 0.0000e+00\n",
            "Epoch 160/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.2704 - acc: 0.0000e+00 - val_loss: 16.3745 - val_acc: 0.0000e+00\n",
            "Epoch 161/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.2670 - acc: 0.0000e+00 - val_loss: 16.3858 - val_acc: 0.0000e+00\n",
            "Epoch 162/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2768 - acc: 0.0000e+00 - val_loss: 16.2661 - val_acc: 0.0000e+00\n",
            "Epoch 163/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.2351 - acc: 0.0000e+00 - val_loss: 16.3531 - val_acc: 0.0000e+00\n",
            "Epoch 164/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.2917 - acc: 0.0000e+00 - val_loss: 16.4804 - val_acc: 0.0000e+00\n",
            "Epoch 165/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2565 - acc: 0.0000e+00 - val_loss: 16.5348 - val_acc: 0.0000e+00\n",
            "Epoch 166/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2373 - acc: 0.0000e+00 - val_loss: 16.3678 - val_acc: 0.0000e+00\n",
            "Epoch 167/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2717 - acc: 0.0000e+00 - val_loss: 16.2263 - val_acc: 0.0000e+00\n",
            "Epoch 168/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.2451 - acc: 0.0000e+00 - val_loss: 16.2252 - val_acc: 0.0000e+00\n",
            "Epoch 169/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.2487 - acc: 0.0000e+00 - val_loss: 16.0537 - val_acc: 0.0000e+00\n",
            "Epoch 170/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.2303 - acc: 0.0000e+00 - val_loss: 16.1537 - val_acc: 0.0000e+00\n",
            "Epoch 171/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2245 - acc: 0.0000e+00 - val_loss: 16.0416 - val_acc: 0.0000e+00\n",
            "Epoch 172/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.2096 - acc: 0.0000e+00 - val_loss: 16.1235 - val_acc: 0.0000e+00\n",
            "Epoch 173/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.1948 - acc: 0.0000e+00 - val_loss: 16.1225 - val_acc: 0.0000e+00\n",
            "Epoch 174/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2068 - acc: 0.0000e+00 - val_loss: 16.0229 - val_acc: 0.0000e+00\n",
            "Epoch 175/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.1982 - acc: 0.0000e+00 - val_loss: 16.2138 - val_acc: 0.0000e+00\n",
            "Epoch 176/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1964 - acc: 0.0000e+00 - val_loss: 16.1315 - val_acc: 0.0000e+00\n",
            "Epoch 177/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1861 - acc: 0.0000e+00 - val_loss: 16.3452 - val_acc: 0.0000e+00\n",
            "Epoch 178/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.1765 - acc: 0.0000e+00 - val_loss: 16.2510 - val_acc: 0.0000e+00\n",
            "Epoch 179/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.2049 - acc: 0.0000e+00 - val_loss: 16.3307 - val_acc: 0.0000e+00\n",
            "Epoch 180/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1766 - acc: 0.0000e+00 - val_loss: 16.3191 - val_acc: 0.0000e+00\n",
            "Epoch 181/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.1655 - acc: 0.0000e+00 - val_loss: 16.1818 - val_acc: 0.0000e+00\n",
            "Epoch 182/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1844 - acc: 0.0000e+00 - val_loss: 16.2392 - val_acc: 0.0000e+00\n",
            "Epoch 183/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1885 - acc: 0.0000e+00 - val_loss: 15.9920 - val_acc: 0.0000e+00\n",
            "Epoch 184/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1513 - acc: 0.0000e+00 - val_loss: 16.1403 - val_acc: 0.0000e+00\n",
            "Epoch 185/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1629 - acc: 0.0000e+00 - val_loss: 16.0112 - val_acc: 0.0000e+00\n",
            "Epoch 186/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1851 - acc: 0.0000e+00 - val_loss: 16.0975 - val_acc: 0.0000e+00\n",
            "Epoch 187/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.1734 - acc: 0.0000e+00 - val_loss: 16.1540 - val_acc: 0.0000e+00\n",
            "Epoch 188/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1182 - acc: 0.0000e+00 - val_loss: 16.0561 - val_acc: 0.0000e+00\n",
            "Epoch 189/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1405 - acc: 0.0000e+00 - val_loss: 15.9032 - val_acc: 0.0000e+00\n",
            "Epoch 190/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1462 - acc: 0.0000e+00 - val_loss: 15.9386 - val_acc: 0.0000e+00\n",
            "Epoch 191/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1026 - acc: 0.0000e+00 - val_loss: 15.9453 - val_acc: 0.0000e+00\n",
            "Epoch 192/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1360 - acc: 0.0000e+00 - val_loss: 16.1730 - val_acc: 0.0000e+00\n",
            "Epoch 193/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1052 - acc: 0.0000e+00 - val_loss: 16.0870 - val_acc: 0.0000e+00\n",
            "Epoch 194/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1290 - acc: 0.0000e+00 - val_loss: 16.1152 - val_acc: 0.0000e+00\n",
            "Epoch 195/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.1163 - acc: 0.0000e+00 - val_loss: 16.0127 - val_acc: 0.0000e+00\n",
            "Epoch 196/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1433 - acc: 0.0000e+00 - val_loss: 15.9531 - val_acc: 0.0000e+00\n",
            "Epoch 197/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.1046 - acc: 0.0000e+00 - val_loss: 16.1957 - val_acc: 0.0000e+00\n",
            "Epoch 198/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1241 - acc: 0.0000e+00 - val_loss: 16.1576 - val_acc: 0.0000e+00\n",
            "Epoch 199/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1048 - acc: 0.0000e+00 - val_loss: 15.8686 - val_acc: 0.0000e+00\n",
            "Epoch 200/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0841 - acc: 0.0000e+00 - val_loss: 15.9062 - val_acc: 0.0000e+00\n",
            "Epoch 201/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0628 - acc: 0.0000e+00 - val_loss: 16.0476 - val_acc: 0.0000e+00\n",
            "Epoch 202/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1000 - acc: 0.0000e+00 - val_loss: 15.9555 - val_acc: 0.0000e+00\n",
            "Epoch 203/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1167 - acc: 0.0000e+00 - val_loss: 16.2157 - val_acc: 0.0000e+00\n",
            "Epoch 204/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0823 - acc: 0.0000e+00 - val_loss: 16.0425 - val_acc: 0.0000e+00\n",
            "Epoch 205/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0660 - acc: 0.0000e+00 - val_loss: 15.8982 - val_acc: 0.0000e+00\n",
            "Epoch 206/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.0668 - acc: 0.0000e+00 - val_loss: 16.0528 - val_acc: 0.0000e+00\n",
            "Epoch 207/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.0695 - acc: 0.0000e+00 - val_loss: 15.9232 - val_acc: 0.0000e+00\n",
            "Epoch 208/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0505 - acc: 0.0000e+00 - val_loss: 15.8900 - val_acc: 0.0000e+00\n",
            "Epoch 209/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0372 - acc: 0.0000e+00 - val_loss: 16.0147 - val_acc: 0.0000e+00\n",
            "Epoch 210/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0647 - acc: 0.0000e+00 - val_loss: 16.0254 - val_acc: 0.0000e+00\n",
            "Epoch 211/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.0403 - acc: 0.0000e+00 - val_loss: 16.0892 - val_acc: 0.0000e+00\n",
            "Epoch 212/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.0328 - acc: 0.0000e+00 - val_loss: 15.9174 - val_acc: 0.0000e+00\n",
            "Epoch 213/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.0173 - acc: 0.0000e+00 - val_loss: 15.8920 - val_acc: 0.0000e+00\n",
            "Epoch 214/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.0161 - acc: 0.0000e+00 - val_loss: 15.9818 - val_acc: 0.0000e+00\n",
            "Epoch 215/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.0255 - acc: 0.0000e+00 - val_loss: 15.8871 - val_acc: 0.0000e+00\n",
            "Epoch 216/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.0210 - acc: 0.0000e+00 - val_loss: 15.7807 - val_acc: 0.0000e+00\n",
            "Epoch 217/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0072 - acc: 0.0000e+00 - val_loss: 15.8135 - val_acc: 0.0000e+00\n",
            "Epoch 218/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9858 - acc: 0.0000e+00 - val_loss: 15.7538 - val_acc: 0.0000e+00\n",
            "Epoch 219/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0250 - acc: 0.0000e+00 - val_loss: 15.6778 - val_acc: 0.0000e+00\n",
            "Epoch 220/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.0045 - acc: 0.0000e+00 - val_loss: 15.8763 - val_acc: 0.0000e+00\n",
            "Epoch 221/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.9751 - acc: 0.0000e+00 - val_loss: 15.8043 - val_acc: 0.0000e+00\n",
            "Epoch 222/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9853 - acc: 0.0000e+00 - val_loss: 15.6163 - val_acc: 0.0000e+00\n",
            "Epoch 223/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.9901 - acc: 0.0000e+00 - val_loss: 15.7501 - val_acc: 0.0000e+00\n",
            "Epoch 224/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.9845 - acc: 0.0000e+00 - val_loss: 16.0440 - val_acc: 0.0000e+00\n",
            "Epoch 225/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.9971 - acc: 0.0000e+00 - val_loss: 15.9488 - val_acc: 0.0000e+00\n",
            "Epoch 226/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9780 - acc: 0.0000e+00 - val_loss: 15.8728 - val_acc: 0.0000e+00\n",
            "Epoch 227/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9700 - acc: 0.0000e+00 - val_loss: 15.8225 - val_acc: 0.0000e+00\n",
            "Epoch 228/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.9713 - acc: 0.0000e+00 - val_loss: 15.6935 - val_acc: 0.0000e+00\n",
            "Epoch 229/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.9915 - acc: 0.0000e+00 - val_loss: 15.7932 - val_acc: 0.0000e+00\n",
            "Epoch 230/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.9450 - acc: 0.0000e+00 - val_loss: 15.7162 - val_acc: 0.0000e+00\n",
            "Epoch 231/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9471 - acc: 0.0000e+00 - val_loss: 15.7355 - val_acc: 0.0000e+00\n",
            "Epoch 232/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9567 - acc: 0.0000e+00 - val_loss: 15.7204 - val_acc: 0.0000e+00\n",
            "Epoch 233/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9416 - acc: 0.0000e+00 - val_loss: 15.7932 - val_acc: 0.0000e+00\n",
            "Epoch 234/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9364 - acc: 0.0000e+00 - val_loss: 15.7327 - val_acc: 0.0000e+00\n",
            "Epoch 235/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.9217 - acc: 0.0000e+00 - val_loss: 15.7449 - val_acc: 0.0000e+00\n",
            "Epoch 236/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9323 - acc: 0.0000e+00 - val_loss: 15.6588 - val_acc: 0.0000e+00\n",
            "Epoch 237/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.9279 - acc: 0.0000e+00 - val_loss: 15.6667 - val_acc: 0.0000e+00\n",
            "Epoch 238/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9422 - acc: 0.0000e+00 - val_loss: 15.7134 - val_acc: 0.0000e+00\n",
            "Epoch 239/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.9187 - acc: 0.0000e+00 - val_loss: 15.9343 - val_acc: 0.0000e+00\n",
            "Epoch 240/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9249 - acc: 0.0000e+00 - val_loss: 15.7842 - val_acc: 0.0000e+00\n",
            "Epoch 241/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9059 - acc: 0.0000e+00 - val_loss: 15.8021 - val_acc: 0.0000e+00\n",
            "Epoch 242/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.9151 - acc: 0.0000e+00 - val_loss: 15.7812 - val_acc: 0.0000e+00\n",
            "Epoch 243/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.9021 - acc: 0.0000e+00 - val_loss: 15.8824 - val_acc: 0.0000e+00\n",
            "Epoch 244/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9056 - acc: 0.0000e+00 - val_loss: 15.7140 - val_acc: 0.0000e+00\n",
            "Epoch 245/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8863 - acc: 0.0000e+00 - val_loss: 15.6293 - val_acc: 0.0000e+00\n",
            "Epoch 246/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.9113 - acc: 0.0000e+00 - val_loss: 15.6944 - val_acc: 0.0000e+00\n",
            "Epoch 247/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9134 - acc: 0.0000e+00 - val_loss: 15.7304 - val_acc: 0.0000e+00\n",
            "Epoch 248/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8858 - acc: 0.0000e+00 - val_loss: 15.5878 - val_acc: 0.0000e+00\n",
            "Epoch 249/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8869 - acc: 0.0000e+00 - val_loss: 15.7272 - val_acc: 0.0000e+00\n",
            "Epoch 250/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9369 - acc: 0.0000e+00 - val_loss: 15.6562 - val_acc: 0.0000e+00\n",
            "Epoch 251/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.8737 - acc: 0.0000e+00 - val_loss: 15.7083 - val_acc: 0.0000e+00\n",
            "Epoch 252/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.8664 - acc: 0.0000e+00 - val_loss: 15.6481 - val_acc: 0.0000e+00\n",
            "Epoch 253/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8780 - acc: 0.0000e+00 - val_loss: 15.5198 - val_acc: 0.0000e+00\n",
            "Epoch 254/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8709 - acc: 0.0000e+00 - val_loss: 15.5267 - val_acc: 0.0000e+00\n",
            "Epoch 255/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.8605 - acc: 0.0000e+00 - val_loss: 15.6906 - val_acc: 0.0000e+00\n",
            "Epoch 256/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8439 - acc: 0.0000e+00 - val_loss: 15.6798 - val_acc: 0.0000e+00\n",
            "Epoch 257/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8662 - acc: 0.0000e+00 - val_loss: 15.5266 - val_acc: 0.0000e+00\n",
            "Epoch 258/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8395 - acc: 0.0000e+00 - val_loss: 15.6926 - val_acc: 0.0000e+00\n",
            "Epoch 259/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.8562 - acc: 0.0000e+00 - val_loss: 15.7304 - val_acc: 0.0000e+00\n",
            "Epoch 260/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8425 - acc: 0.0000e+00 - val_loss: 15.4390 - val_acc: 0.0000e+00\n",
            "Epoch 261/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8428 - acc: 0.0000e+00 - val_loss: 15.3750 - val_acc: 0.0000e+00\n",
            "Epoch 262/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8315 - acc: 0.0000e+00 - val_loss: 15.3893 - val_acc: 0.0000e+00\n",
            "Epoch 263/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8356 - acc: 0.0000e+00 - val_loss: 15.5560 - val_acc: 0.0000e+00\n",
            "Epoch 264/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.8320 - acc: 0.0000e+00 - val_loss: 15.7934 - val_acc: 0.0000e+00\n",
            "Epoch 265/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8219 - acc: 0.0000e+00 - val_loss: 15.6167 - val_acc: 0.0000e+00\n",
            "Epoch 266/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8324 - acc: 0.0000e+00 - val_loss: 15.5263 - val_acc: 0.0000e+00\n",
            "Epoch 267/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.8218 - acc: 0.0000e+00 - val_loss: 15.4694 - val_acc: 0.0000e+00\n",
            "Epoch 268/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8077 - acc: 0.0000e+00 - val_loss: 15.5874 - val_acc: 0.0000e+00\n",
            "Epoch 269/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8068 - acc: 0.0000e+00 - val_loss: 15.5879 - val_acc: 0.0000e+00\n",
            "Epoch 270/500\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.8306 - acc: 0.0000e+00 - val_loss: 15.7592 - val_acc: 0.0000e+00\n",
            "Epoch 271/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8158 - acc: 0.0000e+00 - val_loss: 15.6210 - val_acc: 0.0000e+00\n",
            "Epoch 272/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8128 - acc: 0.0000e+00 - val_loss: 15.5070 - val_acc: 0.0000e+00\n",
            "Epoch 273/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7888 - acc: 0.0000e+00 - val_loss: 15.5774 - val_acc: 0.0000e+00\n",
            "Epoch 274/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7909 - acc: 0.0000e+00 - val_loss: 15.5459 - val_acc: 0.0000e+00\n",
            "Epoch 275/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7956 - acc: 0.0000e+00 - val_loss: 15.6291 - val_acc: 0.0000e+00\n",
            "Epoch 276/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7999 - acc: 0.0000e+00 - val_loss: 15.4765 - val_acc: 0.0000e+00\n",
            "Epoch 277/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7686 - acc: 0.0000e+00 - val_loss: 15.4652 - val_acc: 0.0000e+00\n",
            "Epoch 278/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7654 - acc: 0.0000e+00 - val_loss: 15.5352 - val_acc: 0.0000e+00\n",
            "Epoch 279/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7752 - acc: 0.0000e+00 - val_loss: 15.4707 - val_acc: 0.0000e+00\n",
            "Epoch 280/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7921 - acc: 0.0000e+00 - val_loss: 15.6953 - val_acc: 0.0000e+00\n",
            "Epoch 281/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7696 - acc: 0.0000e+00 - val_loss: 15.4688 - val_acc: 0.0000e+00\n",
            "Epoch 282/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7550 - acc: 0.0000e+00 - val_loss: 15.4117 - val_acc: 0.0000e+00\n",
            "Epoch 283/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7673 - acc: 0.0000e+00 - val_loss: 15.4237 - val_acc: 0.0000e+00\n",
            "Epoch 284/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7901 - acc: 0.0000e+00 - val_loss: 15.2214 - val_acc: 0.0000e+00\n",
            "Epoch 285/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7422 - acc: 0.0000e+00 - val_loss: 15.4001 - val_acc: 0.0000e+00\n",
            "Epoch 286/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.7529 - acc: 0.0000e+00 - val_loss: 15.5361 - val_acc: 0.0000e+00\n",
            "Epoch 287/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7589 - acc: 0.0000e+00 - val_loss: 15.5438 - val_acc: 0.0000e+00\n",
            "Epoch 288/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7510 - acc: 0.0000e+00 - val_loss: 15.4874 - val_acc: 0.0000e+00\n",
            "Epoch 289/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7670 - acc: 0.0000e+00 - val_loss: 15.3013 - val_acc: 0.0000e+00\n",
            "Epoch 290/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.7398 - acc: 0.0000e+00 - val_loss: 15.4426 - val_acc: 0.0000e+00\n",
            "Epoch 291/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7714 - acc: 0.0000e+00 - val_loss: 15.5508 - val_acc: 0.0000e+00\n",
            "Epoch 292/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7281 - acc: 0.0000e+00 - val_loss: 15.3720 - val_acc: 0.0000e+00\n",
            "Epoch 293/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7270 - acc: 0.0000e+00 - val_loss: 15.3197 - val_acc: 0.0000e+00\n",
            "Epoch 294/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7368 - acc: 0.0000e+00 - val_loss: 15.5256 - val_acc: 0.0000e+00\n",
            "Epoch 295/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7295 - acc: 0.0000e+00 - val_loss: 15.5111 - val_acc: 0.0000e+00\n",
            "Epoch 296/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.7509 - acc: 0.0000e+00 - val_loss: 15.3688 - val_acc: 0.0000e+00\n",
            "Epoch 297/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7181 - acc: 0.0000e+00 - val_loss: 15.5012 - val_acc: 0.0000e+00\n",
            "Epoch 298/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.7339 - acc: 0.0000e+00 - val_loss: 15.6418 - val_acc: 0.0000e+00\n",
            "Epoch 299/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7339 - acc: 0.0000e+00 - val_loss: 15.5790 - val_acc: 0.0000e+00\n",
            "Epoch 300/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7119 - acc: 0.0000e+00 - val_loss: 15.5214 - val_acc: 0.0000e+00\n",
            "Epoch 301/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7072 - acc: 0.0000e+00 - val_loss: 15.4060 - val_acc: 0.0000e+00\n",
            "Epoch 302/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7109 - acc: 0.0000e+00 - val_loss: 15.3236 - val_acc: 0.0000e+00\n",
            "Epoch 303/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7048 - acc: 0.0000e+00 - val_loss: 15.3265 - val_acc: 0.0000e+00\n",
            "Epoch 304/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7193 - acc: 0.0000e+00 - val_loss: 15.3412 - val_acc: 0.0000e+00\n",
            "Epoch 305/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7312 - acc: 0.0000e+00 - val_loss: 15.4818 - val_acc: 0.0000e+00\n",
            "Epoch 306/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7163 - acc: 0.0000e+00 - val_loss: 15.3818 - val_acc: 0.0000e+00\n",
            "Epoch 307/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7014 - acc: 0.0000e+00 - val_loss: 15.2779 - val_acc: 0.0000e+00\n",
            "Epoch 308/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7102 - acc: 0.0000e+00 - val_loss: 15.4287 - val_acc: 0.0000e+00\n",
            "Epoch 309/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6755 - acc: 0.0000e+00 - val_loss: 15.3383 - val_acc: 0.0000e+00\n",
            "Epoch 310/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6785 - acc: 0.0000e+00 - val_loss: 15.2495 - val_acc: 0.0000e+00\n",
            "Epoch 311/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6798 - acc: 0.0000e+00 - val_loss: 15.2805 - val_acc: 0.0000e+00\n",
            "Epoch 312/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.6782 - acc: 0.0000e+00 - val_loss: 15.3701 - val_acc: 0.0000e+00\n",
            "Epoch 313/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6696 - acc: 0.0000e+00 - val_loss: 15.4425 - val_acc: 0.0000e+00\n",
            "Epoch 314/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.6606 - acc: 0.0000e+00 - val_loss: 15.3689 - val_acc: 0.0000e+00\n",
            "Epoch 315/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7024 - acc: 0.0000e+00 - val_loss: 15.3300 - val_acc: 0.0000e+00\n",
            "Epoch 316/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6908 - acc: 0.0000e+00 - val_loss: 15.5607 - val_acc: 0.0000e+00\n",
            "Epoch 317/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.6805 - acc: 0.0000e+00 - val_loss: 15.6258 - val_acc: 0.0000e+00\n",
            "Epoch 318/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.6933 - acc: 0.0000e+00 - val_loss: 15.3512 - val_acc: 0.0000e+00\n",
            "Epoch 319/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6562 - acc: 0.0000e+00 - val_loss: 15.3056 - val_acc: 0.0000e+00\n",
            "Epoch 320/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6632 - acc: 0.0000e+00 - val_loss: 15.4849 - val_acc: 0.0000e+00\n",
            "Epoch 321/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6415 - acc: 0.0000e+00 - val_loss: 15.2145 - val_acc: 0.0000e+00\n",
            "Epoch 322/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.6473 - acc: 0.0000e+00 - val_loss: 15.2585 - val_acc: 0.0000e+00\n",
            "Epoch 323/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6292 - acc: 0.0000e+00 - val_loss: 15.1599 - val_acc: 0.0000e+00\n",
            "Epoch 324/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.6262 - acc: 0.0000e+00 - val_loss: 15.1593 - val_acc: 0.0000e+00\n",
            "Epoch 325/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6317 - acc: 0.0000e+00 - val_loss: 15.1755 - val_acc: 0.0000e+00\n",
            "Epoch 326/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6357 - acc: 0.0000e+00 - val_loss: 15.4182 - val_acc: 0.0000e+00\n",
            "Epoch 327/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6358 - acc: 0.0000e+00 - val_loss: 15.3039 - val_acc: 0.0000e+00\n",
            "Epoch 328/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6107 - acc: 0.0000e+00 - val_loss: 15.2414 - val_acc: 0.0000e+00\n",
            "Epoch 329/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6080 - acc: 0.0000e+00 - val_loss: 15.2844 - val_acc: 0.0000e+00\n",
            "Epoch 330/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5972 - acc: 0.0000e+00 - val_loss: 15.2285 - val_acc: 0.0000e+00\n",
            "Epoch 331/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6106 - acc: 0.0000e+00 - val_loss: 15.3138 - val_acc: 0.0000e+00\n",
            "Epoch 332/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5881 - acc: 0.0000e+00 - val_loss: 15.1572 - val_acc: 0.0000e+00\n",
            "Epoch 333/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5980 - acc: 0.0000e+00 - val_loss: 15.0832 - val_acc: 0.0000e+00\n",
            "Epoch 334/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6000 - acc: 0.0000e+00 - val_loss: 15.1248 - val_acc: 0.0000e+00\n",
            "Epoch 335/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5873 - acc: 0.0000e+00 - val_loss: 15.0323 - val_acc: 0.0000e+00\n",
            "Epoch 336/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6256 - acc: 0.0000e+00 - val_loss: 14.9860 - val_acc: 0.0000e+00\n",
            "Epoch 337/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6159 - acc: 0.0000e+00 - val_loss: 15.1043 - val_acc: 0.0000e+00\n",
            "Epoch 338/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5949 - acc: 0.0000e+00 - val_loss: 15.2535 - val_acc: 0.0000e+00\n",
            "Epoch 339/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5676 - acc: 0.0000e+00 - val_loss: 15.1053 - val_acc: 0.0000e+00\n",
            "Epoch 340/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.5780 - acc: 0.0000e+00 - val_loss: 15.0251 - val_acc: 0.0000e+00\n",
            "Epoch 341/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5720 - acc: 0.0000e+00 - val_loss: 15.1747 - val_acc: 0.0000e+00\n",
            "Epoch 342/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5719 - acc: 0.0000e+00 - val_loss: 15.1032 - val_acc: 0.0000e+00\n",
            "Epoch 343/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5610 - acc: 0.0000e+00 - val_loss: 15.1927 - val_acc: 0.0000e+00\n",
            "Epoch 344/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5773 - acc: 0.0000e+00 - val_loss: 14.9103 - val_acc: 0.0000e+00\n",
            "Epoch 345/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5833 - acc: 0.0000e+00 - val_loss: 15.0123 - val_acc: 0.0000e+00\n",
            "Epoch 346/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.5550 - acc: 0.0000e+00 - val_loss: 14.9465 - val_acc: 0.0000e+00\n",
            "Epoch 347/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5452 - acc: 0.0000e+00 - val_loss: 15.1398 - val_acc: 0.0000e+00\n",
            "Epoch 348/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5496 - acc: 0.0000e+00 - val_loss: 15.3171 - val_acc: 0.0000e+00\n",
            "Epoch 349/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5794 - acc: 0.0000e+00 - val_loss: 15.1446 - val_acc: 0.0000e+00\n",
            "Epoch 350/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5716 - acc: 0.0000e+00 - val_loss: 15.2468 - val_acc: 0.0000e+00\n",
            "Epoch 351/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5365 - acc: 0.0000e+00 - val_loss: 14.9854 - val_acc: 0.0000e+00\n",
            "Epoch 352/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5673 - acc: 0.0000e+00 - val_loss: 14.9749 - val_acc: 0.0000e+00\n",
            "Epoch 353/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.5442 - acc: 0.0000e+00 - val_loss: 15.0217 - val_acc: 0.0000e+00\n",
            "Epoch 354/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.5362 - acc: 0.0000e+00 - val_loss: 14.8924 - val_acc: 0.0000e+00\n",
            "Epoch 355/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5311 - acc: 0.0000e+00 - val_loss: 14.9325 - val_acc: 0.0000e+00\n",
            "Epoch 356/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.5154 - acc: 0.0000e+00 - val_loss: 14.8698 - val_acc: 0.0000e+00\n",
            "Epoch 357/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.5134 - acc: 0.0000e+00 - val_loss: 14.9147 - val_acc: 0.0000e+00\n",
            "Epoch 358/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.5292 - acc: 0.0000e+00 - val_loss: 15.1693 - val_acc: 0.0000e+00\n",
            "Epoch 359/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5321 - acc: 0.0000e+00 - val_loss: 15.1450 - val_acc: 0.0000e+00\n",
            "Epoch 360/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5099 - acc: 0.0000e+00 - val_loss: 15.0250 - val_acc: 0.0000e+00\n",
            "Epoch 361/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5873 - acc: 0.0000e+00 - val_loss: 14.6671 - val_acc: 0.0000e+00\n",
            "Epoch 362/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.5187 - acc: 0.0000e+00 - val_loss: 15.0617 - val_acc: 0.0000e+00\n",
            "Epoch 363/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5039 - acc: 0.0000e+00 - val_loss: 15.1421 - val_acc: 0.0000e+00\n",
            "Epoch 364/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5019 - acc: 0.0000e+00 - val_loss: 15.0455 - val_acc: 0.0000e+00\n",
            "Epoch 365/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5097 - acc: 0.0000e+00 - val_loss: 15.1774 - val_acc: 0.0000e+00\n",
            "Epoch 366/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.4857 - acc: 0.0000e+00 - val_loss: 15.0522 - val_acc: 0.0000e+00\n",
            "Epoch 367/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.4849 - acc: 0.0000e+00 - val_loss: 15.0162 - val_acc: 0.0000e+00\n",
            "Epoch 368/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4869 - acc: 0.0000e+00 - val_loss: 14.8318 - val_acc: 0.0000e+00\n",
            "Epoch 369/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4866 - acc: 0.0000e+00 - val_loss: 14.8963 - val_acc: 0.0000e+00\n",
            "Epoch 370/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4927 - acc: 0.0000e+00 - val_loss: 15.1547 - val_acc: 0.0000e+00\n",
            "Epoch 371/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4800 - acc: 0.0000e+00 - val_loss: 15.0667 - val_acc: 0.0000e+00\n",
            "Epoch 372/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4742 - acc: 0.0000e+00 - val_loss: 15.0559 - val_acc: 0.0000e+00\n",
            "Epoch 373/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.4759 - acc: 0.0000e+00 - val_loss: 15.0308 - val_acc: 0.0000e+00\n",
            "Epoch 374/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4666 - acc: 0.0000e+00 - val_loss: 15.0085 - val_acc: 0.0000e+00\n",
            "Epoch 375/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4722 - acc: 0.0000e+00 - val_loss: 15.1037 - val_acc: 0.0000e+00\n",
            "Epoch 376/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4646 - acc: 0.0000e+00 - val_loss: 14.9307 - val_acc: 0.0000e+00\n",
            "Epoch 377/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4536 - acc: 0.0000e+00 - val_loss: 15.0271 - val_acc: 0.0000e+00\n",
            "Epoch 378/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4735 - acc: 0.0000e+00 - val_loss: 15.1226 - val_acc: 0.0000e+00\n",
            "Epoch 379/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4810 - acc: 0.0000e+00 - val_loss: 14.9306 - val_acc: 0.0000e+00\n",
            "Epoch 380/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4450 - acc: 0.0000e+00 - val_loss: 14.9281 - val_acc: 0.0000e+00\n",
            "Epoch 381/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.4569 - acc: 0.0000e+00 - val_loss: 14.8571 - val_acc: 0.0000e+00\n",
            "Epoch 382/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4574 - acc: 0.0000e+00 - val_loss: 14.8365 - val_acc: 0.0000e+00\n",
            "Epoch 383/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.4597 - acc: 0.0000e+00 - val_loss: 15.1748 - val_acc: 0.0000e+00\n",
            "Epoch 384/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4641 - acc: 0.0000e+00 - val_loss: 15.1979 - val_acc: 0.0000e+00\n",
            "Epoch 385/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4532 - acc: 0.0000e+00 - val_loss: 14.9099 - val_acc: 0.0000e+00\n",
            "Epoch 386/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4432 - acc: 0.0000e+00 - val_loss: 14.7953 - val_acc: 0.0000e+00\n",
            "Epoch 387/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4423 - acc: 0.0000e+00 - val_loss: 14.6880 - val_acc: 0.0000e+00\n",
            "Epoch 388/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4503 - acc: 0.0000e+00 - val_loss: 14.8570 - val_acc: 0.0000e+00\n",
            "Epoch 389/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.4367 - acc: 0.0000e+00 - val_loss: 14.8964 - val_acc: 0.0000e+00\n",
            "Epoch 390/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4291 - acc: 0.0000e+00 - val_loss: 14.8483 - val_acc: 0.0000e+00\n",
            "Epoch 391/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4227 - acc: 0.0000e+00 - val_loss: 14.8183 - val_acc: 0.0000e+00\n",
            "Epoch 392/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.4212 - acc: 0.0000e+00 - val_loss: 14.9009 - val_acc: 0.0000e+00\n",
            "Epoch 393/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4332 - acc: 0.0000e+00 - val_loss: 14.9960 - val_acc: 0.0000e+00\n",
            "Epoch 394/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.4449 - acc: 0.0000e+00 - val_loss: 14.9553 - val_acc: 0.0000e+00\n",
            "Epoch 395/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4213 - acc: 0.0000e+00 - val_loss: 15.0053 - val_acc: 0.0000e+00\n",
            "Epoch 396/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.4087 - acc: 0.0000e+00 - val_loss: 14.8452 - val_acc: 0.0000e+00\n",
            "Epoch 397/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4203 - acc: 0.0000e+00 - val_loss: 14.8058 - val_acc: 0.0000e+00\n",
            "Epoch 398/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.4003 - acc: 0.0000e+00 - val_loss: 14.8823 - val_acc: 0.0000e+00\n",
            "Epoch 399/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.4226 - acc: 0.0000e+00 - val_loss: 15.1966 - val_acc: 0.0000e+00\n",
            "Epoch 400/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4188 - acc: 0.0000e+00 - val_loss: 15.1036 - val_acc: 0.0000e+00\n",
            "Epoch 401/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3972 - acc: 0.0000e+00 - val_loss: 14.8830 - val_acc: 0.0000e+00\n",
            "Epoch 402/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4072 - acc: 0.0000e+00 - val_loss: 14.8688 - val_acc: 0.0000e+00\n",
            "Epoch 403/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3896 - acc: 0.0000e+00 - val_loss: 15.0286 - val_acc: 0.0000e+00\n",
            "Epoch 404/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4063 - acc: 0.0000e+00 - val_loss: 15.0853 - val_acc: 0.0000e+00\n",
            "Epoch 405/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4008 - acc: 0.0000e+00 - val_loss: 15.0404 - val_acc: 0.0000e+00\n",
            "Epoch 406/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4051 - acc: 0.0000e+00 - val_loss: 14.7500 - val_acc: 0.0000e+00\n",
            "Epoch 407/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.4023 - acc: 0.0000e+00 - val_loss: 14.7964 - val_acc: 0.0000e+00\n",
            "Epoch 408/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3676 - acc: 0.0000e+00 - val_loss: 14.8508 - val_acc: 0.0000e+00\n",
            "Epoch 409/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3826 - acc: 0.0000e+00 - val_loss: 14.9128 - val_acc: 0.0000e+00\n",
            "Epoch 410/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3839 - acc: 0.0000e+00 - val_loss: 14.8372 - val_acc: 0.0000e+00\n",
            "Epoch 411/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3810 - acc: 0.0000e+00 - val_loss: 14.9739 - val_acc: 0.0000e+00\n",
            "Epoch 412/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3644 - acc: 0.0000e+00 - val_loss: 14.9643 - val_acc: 0.0000e+00\n",
            "Epoch 413/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4043 - acc: 0.0000e+00 - val_loss: 14.9260 - val_acc: 0.0000e+00\n",
            "Epoch 414/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3577 - acc: 0.0000e+00 - val_loss: 14.6477 - val_acc: 0.0000e+00\n",
            "Epoch 415/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3795 - acc: 0.0000e+00 - val_loss: 14.6603 - val_acc: 0.0000e+00\n",
            "Epoch 416/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3748 - acc: 0.0000e+00 - val_loss: 14.6448 - val_acc: 0.0000e+00\n",
            "Epoch 417/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3617 - acc: 0.0000e+00 - val_loss: 14.9296 - val_acc: 0.0000e+00\n",
            "Epoch 418/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3836 - acc: 0.0000e+00 - val_loss: 14.9305 - val_acc: 0.0000e+00\n",
            "Epoch 419/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3750 - acc: 0.0000e+00 - val_loss: 14.6111 - val_acc: 0.0000e+00\n",
            "Epoch 420/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3846 - acc: 0.0000e+00 - val_loss: 14.7560 - val_acc: 0.0000e+00\n",
            "Epoch 421/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3525 - acc: 0.0000e+00 - val_loss: 14.7032 - val_acc: 0.0000e+00\n",
            "Epoch 422/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.3476 - acc: 0.0000e+00 - val_loss: 14.8427 - val_acc: 0.0000e+00\n",
            "Epoch 423/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3401 - acc: 0.0000e+00 - val_loss: 14.9955 - val_acc: 0.0000e+00\n",
            "Epoch 424/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.3803 - acc: 0.0000e+00 - val_loss: 14.6941 - val_acc: 0.0000e+00\n",
            "Epoch 425/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3309 - acc: 0.0000e+00 - val_loss: 14.7693 - val_acc: 0.0000e+00\n",
            "Epoch 426/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3357 - acc: 0.0000e+00 - val_loss: 14.8006 - val_acc: 0.0000e+00\n",
            "Epoch 427/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3387 - acc: 0.0000e+00 - val_loss: 14.6576 - val_acc: 0.0000e+00\n",
            "Epoch 428/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3364 - acc: 0.0000e+00 - val_loss: 14.6643 - val_acc: 0.0000e+00\n",
            "Epoch 429/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3559 - acc: 0.0000e+00 - val_loss: 14.7520 - val_acc: 0.0000e+00\n",
            "Epoch 430/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3243 - acc: 0.0000e+00 - val_loss: 14.6684 - val_acc: 0.0000e+00\n",
            "Epoch 431/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3195 - acc: 0.0000e+00 - val_loss: 14.6703 - val_acc: 0.0000e+00\n",
            "Epoch 432/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3268 - acc: 0.0000e+00 - val_loss: 14.7137 - val_acc: 0.0000e+00\n",
            "Epoch 433/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3176 - acc: 0.0000e+00 - val_loss: 14.5065 - val_acc: 0.0000e+00\n",
            "Epoch 434/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3268 - acc: 0.0000e+00 - val_loss: 14.4907 - val_acc: 0.0000e+00\n",
            "Epoch 435/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3251 - acc: 0.0000e+00 - val_loss: 14.6714 - val_acc: 0.0000e+00\n",
            "Epoch 436/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3182 - acc: 0.0000e+00 - val_loss: 14.6560 - val_acc: 0.0000e+00\n",
            "Epoch 437/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3012 - acc: 0.0000e+00 - val_loss: 14.7497 - val_acc: 0.0000e+00\n",
            "Epoch 438/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2982 - acc: 0.0000e+00 - val_loss: 14.7763 - val_acc: 0.0000e+00\n",
            "Epoch 439/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3084 - acc: 0.0000e+00 - val_loss: 14.5641 - val_acc: 0.0000e+00\n",
            "Epoch 440/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2979 - acc: 0.0000e+00 - val_loss: 14.5216 - val_acc: 0.0000e+00\n",
            "Epoch 441/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3193 - acc: 0.0000e+00 - val_loss: 14.8117 - val_acc: 0.0000e+00\n",
            "Epoch 442/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3067 - acc: 0.0000e+00 - val_loss: 14.5567 - val_acc: 0.0000e+00\n",
            "Epoch 443/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2769 - acc: 0.0000e+00 - val_loss: 14.6472 - val_acc: 0.0000e+00\n",
            "Epoch 444/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2756 - acc: 0.0000e+00 - val_loss: 14.6850 - val_acc: 0.0000e+00\n",
            "Epoch 445/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3066 - acc: 0.0000e+00 - val_loss: 14.8430 - val_acc: 0.0000e+00\n",
            "Epoch 446/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2924 - acc: 0.0000e+00 - val_loss: 14.6149 - val_acc: 0.0000e+00\n",
            "Epoch 447/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2843 - acc: 0.0000e+00 - val_loss: 14.6247 - val_acc: 0.0000e+00\n",
            "Epoch 448/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2684 - acc: 0.0000e+00 - val_loss: 14.7057 - val_acc: 0.0000e+00\n",
            "Epoch 449/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2672 - acc: 0.0000e+00 - val_loss: 14.6123 - val_acc: 0.0000e+00\n",
            "Epoch 450/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2745 - acc: 0.0000e+00 - val_loss: 14.4330 - val_acc: 0.0000e+00\n",
            "Epoch 451/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2722 - acc: 0.0000e+00 - val_loss: 14.5726 - val_acc: 0.0000e+00\n",
            "Epoch 452/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2565 - acc: 0.0000e+00 - val_loss: 14.7038 - val_acc: 0.0000e+00\n",
            "Epoch 453/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2864 - acc: 0.0000e+00 - val_loss: 14.5981 - val_acc: 0.0000e+00\n",
            "Epoch 454/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2607 - acc: 0.0000e+00 - val_loss: 14.6432 - val_acc: 0.0000e+00\n",
            "Epoch 455/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2602 - acc: 0.0000e+00 - val_loss: 14.7718 - val_acc: 0.0000e+00\n",
            "Epoch 456/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2877 - acc: 0.0000e+00 - val_loss: 14.7057 - val_acc: 0.0000e+00\n",
            "Epoch 457/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2394 - acc: 0.0000e+00 - val_loss: 14.5616 - val_acc: 0.0000e+00\n",
            "Epoch 458/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2398 - acc: 0.0000e+00 - val_loss: 14.5441 - val_acc: 0.0000e+00\n",
            "Epoch 459/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2482 - acc: 0.0000e+00 - val_loss: 14.6106 - val_acc: 0.0000e+00\n",
            "Epoch 460/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2541 - acc: 0.0000e+00 - val_loss: 14.3920 - val_acc: 0.0000e+00\n",
            "Epoch 461/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2390 - acc: 0.0000e+00 - val_loss: 14.5046 - val_acc: 0.0000e+00\n",
            "Epoch 462/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2466 - acc: 0.0000e+00 - val_loss: 14.6918 - val_acc: 0.0000e+00\n",
            "Epoch 463/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2453 - acc: 0.0000e+00 - val_loss: 14.5150 - val_acc: 0.0000e+00\n",
            "Epoch 464/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2208 - acc: 0.0000e+00 - val_loss: 14.4505 - val_acc: 0.0000e+00\n",
            "Epoch 465/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2337 - acc: 0.0000e+00 - val_loss: 14.5431 - val_acc: 0.0000e+00\n",
            "Epoch 466/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2557 - acc: 0.0000e+00 - val_loss: 14.5367 - val_acc: 0.0000e+00\n",
            "Epoch 467/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2333 - acc: 0.0000e+00 - val_loss: 14.5322 - val_acc: 0.0000e+00\n",
            "Epoch 468/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2107 - acc: 0.0000e+00 - val_loss: 14.5426 - val_acc: 0.0000e+00\n",
            "Epoch 469/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2283 - acc: 0.0000e+00 - val_loss: 14.5052 - val_acc: 0.0000e+00\n",
            "Epoch 470/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2120 - acc: 0.0000e+00 - val_loss: 14.4653 - val_acc: 0.0000e+00\n",
            "Epoch 471/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2039 - acc: 0.0000e+00 - val_loss: 14.5365 - val_acc: 0.0000e+00\n",
            "Epoch 472/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2220 - acc: 0.0000e+00 - val_loss: 14.6430 - val_acc: 0.0000e+00\n",
            "Epoch 473/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2315 - acc: 0.0000e+00 - val_loss: 14.6042 - val_acc: 0.0000e+00\n",
            "Epoch 474/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2069 - acc: 0.0000e+00 - val_loss: 14.4659 - val_acc: 0.0000e+00\n",
            "Epoch 475/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.1987 - acc: 0.0000e+00 - val_loss: 14.5323 - val_acc: 0.0000e+00\n",
            "Epoch 476/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.1887 - acc: 0.0000e+00 - val_loss: 14.4942 - val_acc: 0.0000e+00\n",
            "Epoch 477/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2014 - acc: 0.0000e+00 - val_loss: 14.3587 - val_acc: 0.0000e+00\n",
            "Epoch 478/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.1957 - acc: 0.0000e+00 - val_loss: 14.5980 - val_acc: 0.0000e+00\n",
            "Epoch 479/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1953 - acc: 0.0000e+00 - val_loss: 14.5197 - val_acc: 0.0000e+00\n",
            "Epoch 480/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2043 - acc: 0.0000e+00 - val_loss: 14.4732 - val_acc: 0.0000e+00\n",
            "Epoch 481/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2138 - acc: 0.0000e+00 - val_loss: 14.5567 - val_acc: 0.0000e+00\n",
            "Epoch 482/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.1702 - acc: 0.0000e+00 - val_loss: 14.5050 - val_acc: 0.0000e+00\n",
            "Epoch 483/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1734 - acc: 0.0000e+00 - val_loss: 14.4796 - val_acc: 0.0000e+00\n",
            "Epoch 484/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2032 - acc: 0.0000e+00 - val_loss: 14.5101 - val_acc: 0.0000e+00\n",
            "Epoch 485/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.1755 - acc: 0.0000e+00 - val_loss: 14.3445 - val_acc: 0.0000e+00\n",
            "Epoch 486/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.2007 - acc: 0.0000e+00 - val_loss: 14.3377 - val_acc: 0.0000e+00\n",
            "Epoch 487/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2109 - acc: 0.0000e+00 - val_loss: 14.5535 - val_acc: 0.0000e+00\n",
            "Epoch 488/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.1713 - acc: 0.0000e+00 - val_loss: 14.6433 - val_acc: 0.0000e+00\n",
            "Epoch 489/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1682 - acc: 0.0000e+00 - val_loss: 14.4791 - val_acc: 0.0000e+00\n",
            "Epoch 490/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1657 - acc: 0.0000e+00 - val_loss: 14.2357 - val_acc: 0.0000e+00\n",
            "Epoch 491/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.1943 - acc: 0.0000e+00 - val_loss: 14.3887 - val_acc: 0.0000e+00\n",
            "Epoch 492/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2135 - acc: 0.0000e+00 - val_loss: 14.5982 - val_acc: 0.0000e+00\n",
            "Epoch 493/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1847 - acc: 0.0000e+00 - val_loss: 14.1323 - val_acc: 0.0000e+00\n",
            "Epoch 494/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1811 - acc: 0.0000e+00 - val_loss: 14.3395 - val_acc: 0.0000e+00\n",
            "Epoch 495/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1558 - acc: 0.0000e+00 - val_loss: 14.3564 - val_acc: 0.0000e+00\n",
            "Epoch 496/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.1452 - acc: 0.0000e+00 - val_loss: 14.5944 - val_acc: 0.0000e+00\n",
            "Epoch 497/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.1893 - acc: 0.0000e+00 - val_loss: 14.5113 - val_acc: 0.0000e+00\n",
            "Epoch 498/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.1763 - acc: 0.0000e+00 - val_loss: 14.2154 - val_acc: 0.0000e+00\n",
            "Epoch 499/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.1472 - acc: 0.0000e+00 - val_loss: 14.2904 - val_acc: 0.0000e+00\n",
            "Epoch 500/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.1532 - acc: 0.0000e+00 - val_loss: 14.3447 - val_acc: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "wF1nFuwFKytr",
        "outputId": "e369d298-d3cb-4fdc-bf78-176fde41af35"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.legend(['loss','val_loss', 'accuracy','val_acc'])\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyFfV_gSOEs3",
        "outputId": "488f58f9-2ff0-4e86-8f1d-1e9c24ed3189"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 9.9868 - acc: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9.986797332763672, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLB_0bX5Lk22",
        "outputId": "6d94abd9-51ce-4383-b98e-5790531c543c"
      },
      "source": [
        "# 텐서에 들어가는 데이터는  차원+1\n",
        "# 주택가격 예측시 아래와 같이 사용함.\n",
        "\n",
        "new_x=[[1,2,3,4,5,6,7,8,9,10,11,12,13]]     # 대괄호를 1개만할시 밸류 error 발생\n",
        "\n",
        "model.predict(new_x)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[51.425083]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1MFkxw0t8Oq"
      },
      "source": [
        "## K-Fold 사용하기\n",
        " - K-Fold CrossValidation\n",
        "  - 모델은 많은 데이터를 보여줄수록 성능이 올라감\n",
        "  - K-Fold 방법을 사용해서 최대한 많은 데이터를 볼 수 있도록 도와줌\n",
        "  - K는 주로 3 ~ 10을 사용\n",
        "\n",
        " - 데이터 개수가 적은 경우, 성능을 향상시킬 수 있는 좋은 방법: 교차검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2NOEFknOQhR",
        "outputId": "aa7a02e7-c5a0-429c-82c0-b30f8afa7844"
      },
      "source": [
        "from tensorflow.keras.datasets.boston_housing import load_data\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                 test_split=0.2,\n",
        "                                                 seed=777)\n",
        "\n",
        "# 데이터 표준화\n",
        "mean = np.mean(x_train, axis = 0)\n",
        "std = np.std(x_train, axis = 0)\n",
        "# 여기까진 전부 동일합니다.\n",
        "x_train = (x_train - mean) / std\n",
        "x_test = (x_test - mean) / std"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "65536/57026 [==================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BANzWWWIuf8y"
      },
      "source": [
        "### K-Fold 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMaeAgD8uaJw",
        "outputId": "75b6c6cc-cb62-42fc-a9fc-d26d5889d500"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "#----------------------------------------\n",
        "# K-Fold를 진행해봅니다.\n",
        "k = 3\n",
        "\n",
        "# 주어진 데이터셋을 k만큼 등분합니다.\n",
        "# 여기서는 3이므로 훈련 데이터셋(404개)를 3등분하여\n",
        "# 1개는 검증셋으로, 나머지 2개는 훈련셋으로 활용합니다.\n",
        "kfold = KFold(n_splits=k, random_state = 777)\n",
        "\n",
        "# 재사용을 위해 모델을 반환하는 함수를 정의합니다.\n",
        "def get_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, activation = 'relu', input_shape = (13, )))\n",
        "    model.add(Dense(32, activation = 'relu')) \n",
        "    model.add(Dense(1))   \n",
        "\n",
        "    model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "mae_list = [] # 테스트셋을 평가한 후 결과 mae를 담을 리스트를 선언합니다.\n",
        "\n",
        "# k번 진행합니다.\n",
        "for train_index, val_index in kfold.split(x_train):\n",
        "    # 해당 인덱스는 무작위로 생성됩니다.\n",
        "    # 무작위로 생성해주는 것은 과대적합을 피할 수 있는 좋은 방법입니다.\n",
        "    x_train_fold, x_val_fold = x_train[train_index], x_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "    \n",
        "    # 모델을 불러옵니다.\n",
        "    model = get_model()\n",
        "    \n",
        "    model.fit(x_train_fold, y_train_fold, epochs = 300, validation_data = (x_val_fold, y_val_fold))\n",
        "    \n",
        "    test_mse, test_mae = model.evaluate(x_test, y_test)\n",
        "    mae_list.append(test_mae)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 24ms/step - loss: 576.1182 - mae: 22.1453 - val_loss: 548.8381 - val_mae: 21.5897\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 546.6316 - mae: 21.4929 - val_loss: 521.0392 - val_mae: 20.9475\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 515.5146 - mae: 20.7779 - val_loss: 489.1298 - val_mae: 20.1837\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 479.3068 - mae: 19.9146 - val_loss: 450.0294 - val_mae: 19.2241\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 432.9510 - mae: 18.7870 - val_loss: 402.0672 - val_mae: 17.9930\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 377.4453 - mae: 17.3677 - val_loss: 346.3574 - val_mae: 16.4724\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 314.9445 - mae: 15.6173 - val_loss: 285.5767 - val_mae: 14.6388\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 253.2314 - mae: 13.6570 - val_loss: 223.2962 - val_mae: 12.5336\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 191.5436 - mae: 11.4558 - val_loss: 169.1324 - val_mae: 10.4814\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 142.7583 - mae: 9.4784 - val_loss: 126.3386 - val_mae: 8.8058\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 107.3366 - mae: 7.9832 - val_loss: 97.5569 - val_mae: 7.6795\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 86.3034 - mae: 7.1580 - val_loss: 78.0984 - val_mae: 6.8586\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 72.2104 - mae: 6.6166 - val_loss: 64.2462 - val_mae: 6.1684\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 61.6226 - mae: 6.1717 - val_loss: 53.7634 - val_mae: 5.6091\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 53.0877 - mae: 5.7499 - val_loss: 44.9026 - val_mae: 5.0885\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 45.3864 - mae: 5.3228 - val_loss: 38.3798 - val_mae: 4.6444\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 39.1267 - mae: 4.9128 - val_loss: 33.2659 - val_mae: 4.2682\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 34.5001 - mae: 4.5498 - val_loss: 29.3298 - val_mae: 4.0001\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 30.9023 - mae: 4.2459 - val_loss: 26.2885 - val_mae: 3.7789\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 28.0535 - mae: 3.9828 - val_loss: 24.2264 - val_mae: 3.6528\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 25.8682 - mae: 3.7742 - val_loss: 22.8859 - val_mae: 3.5533\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 24.2083 - mae: 3.6008 - val_loss: 21.8699 - val_mae: 3.4703\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 22.9961 - mae: 3.4707 - val_loss: 21.0632 - val_mae: 3.4192\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 21.9854 - mae: 3.3646 - val_loss: 20.5191 - val_mae: 3.3797\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 21.1008 - mae: 3.2675 - val_loss: 20.1826 - val_mae: 3.3447\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 20.3333 - mae: 3.1909 - val_loss: 19.9422 - val_mae: 3.3153\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 19.7667 - mae: 3.1293 - val_loss: 19.7451 - val_mae: 3.2900\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 19.2465 - mae: 3.0744 - val_loss: 19.5006 - val_mae: 3.2816\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 18.7446 - mae: 3.0262 - val_loss: 19.4570 - val_mae: 3.2567\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 18.2598 - mae: 2.9678 - val_loss: 19.3019 - val_mae: 3.2390\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 17.8814 - mae: 2.9275 - val_loss: 19.0981 - val_mae: 3.2283\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 17.5039 - mae: 2.8988 - val_loss: 18.9395 - val_mae: 3.2174\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 17.1577 - mae: 2.8710 - val_loss: 18.8647 - val_mae: 3.2090\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.8431 - mae: 2.8391 - val_loss: 18.8049 - val_mae: 3.1966\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.5883 - mae: 2.8137 - val_loss: 18.6790 - val_mae: 3.1944\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.2892 - mae: 2.7923 - val_loss: 18.5756 - val_mae: 3.1807\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 16.0290 - mae: 2.7692 - val_loss: 18.4487 - val_mae: 3.1731\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.7129 - mae: 2.7477 - val_loss: 18.4706 - val_mae: 3.1827\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.6512 - mae: 2.7452 - val_loss: 18.3578 - val_mae: 3.1770\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.2074 - mae: 2.7055 - val_loss: 18.3111 - val_mae: 3.1698\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 15.0940 - mae: 2.6723 - val_loss: 18.2956 - val_mae: 3.1533\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.8466 - mae: 2.6582 - val_loss: 18.1610 - val_mae: 3.1521\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.6228 - mae: 2.6507 - val_loss: 17.9845 - val_mae: 3.1523\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 14.3919 - mae: 2.6426 - val_loss: 17.9375 - val_mae: 3.1426\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.2163 - mae: 2.6253 - val_loss: 17.8795 - val_mae: 3.1337\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 13.9835 - mae: 2.6001 - val_loss: 17.7716 - val_mae: 3.1241\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.8491 - mae: 2.5829 - val_loss: 17.7658 - val_mae: 3.1224\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 13.6961 - mae: 2.5749 - val_loss: 17.6022 - val_mae: 3.1028\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.4991 - mae: 2.5514 - val_loss: 17.6285 - val_mae: 3.1006\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.3160 - mae: 2.5315 - val_loss: 17.5217 - val_mae: 3.0880\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 13.1625 - mae: 2.5187 - val_loss: 17.3110 - val_mae: 3.0815\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.9498 - mae: 2.5081 - val_loss: 17.2489 - val_mae: 3.0786\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12.7896 - mae: 2.4941 - val_loss: 17.1537 - val_mae: 3.0660\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12.6708 - mae: 2.4912 - val_loss: 17.0316 - val_mae: 3.0744\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.5877 - mae: 2.4935 - val_loss: 17.0131 - val_mae: 3.0810\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.3131 - mae: 2.4692 - val_loss: 17.0219 - val_mae: 3.0664\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12.2288 - mae: 2.4481 - val_loss: 17.0113 - val_mae: 3.0511\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.0876 - mae: 2.4400 - val_loss: 16.8792 - val_mae: 3.0423\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.9330 - mae: 2.4246 - val_loss: 16.7159 - val_mae: 3.0342\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 11.7732 - mae: 2.4204 - val_loss: 16.6255 - val_mae: 3.0322\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.6994 - mae: 2.4167 - val_loss: 16.4715 - val_mae: 3.0191\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 11.6033 - mae: 2.4059 - val_loss: 16.5697 - val_mae: 3.0247\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.4166 - mae: 2.3838 - val_loss: 16.4212 - val_mae: 3.0106\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.2807 - mae: 2.3777 - val_loss: 16.3365 - val_mae: 3.0053\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 11.2169 - mae: 2.3764 - val_loss: 16.3688 - val_mae: 3.0060\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.1581 - mae: 2.3595 - val_loss: 16.3010 - val_mae: 2.9863\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.9783 - mae: 2.3433 - val_loss: 16.2112 - val_mae: 2.9804\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.8934 - mae: 2.3395 - val_loss: 16.0988 - val_mae: 2.9776\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.7624 - mae: 2.3305 - val_loss: 16.0335 - val_mae: 2.9743\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.6713 - mae: 2.3133 - val_loss: 16.0712 - val_mae: 2.9632\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.5804 - mae: 2.3006 - val_loss: 15.9885 - val_mae: 2.9614\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4546 - mae: 2.2935 - val_loss: 15.9073 - val_mae: 2.9600\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.4528 - mae: 2.2998 - val_loss: 15.7819 - val_mae: 2.9537\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.3757 - mae: 2.2882 - val_loss: 15.8492 - val_mae: 2.9660\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.2324 - mae: 2.2709 - val_loss: 15.9202 - val_mae: 2.9584\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.0943 - mae: 2.2517 - val_loss: 15.7593 - val_mae: 2.9336\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.0951 - mae: 2.2545 - val_loss: 15.5735 - val_mae: 2.9229\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.9574 - mae: 2.2453 - val_loss: 15.4923 - val_mae: 2.9214\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.8811 - mae: 2.2358 - val_loss: 15.4577 - val_mae: 2.9179\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.7990 - mae: 2.2254 - val_loss: 15.4895 - val_mae: 2.9168\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.7176 - mae: 2.2148 - val_loss: 15.3718 - val_mae: 2.9107\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.6081 - mae: 2.2027 - val_loss: 15.3745 - val_mae: 2.9285\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.6366 - mae: 2.2100 - val_loss: 15.2413 - val_mae: 2.9059\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4860 - mae: 2.1898 - val_loss: 15.2567 - val_mae: 2.9019\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4339 - mae: 2.1861 - val_loss: 15.3069 - val_mae: 2.9046\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.3850 - mae: 2.1731 - val_loss: 15.1193 - val_mae: 2.8950\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.2471 - mae: 2.1607 - val_loss: 15.0558 - val_mae: 2.8852\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1477 - mae: 2.1571 - val_loss: 14.9958 - val_mae: 2.8851\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1553 - mae: 2.1588 - val_loss: 14.9669 - val_mae: 2.8779\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.0932 - mae: 2.1567 - val_loss: 15.0618 - val_mae: 2.9017\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9911 - mae: 2.1373 - val_loss: 14.9247 - val_mae: 2.8787\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.0441 - mae: 2.1412 - val_loss: 14.8135 - val_mae: 2.8742\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8842 - mae: 2.1209 - val_loss: 14.8567 - val_mae: 2.8680\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7924 - mae: 2.1044 - val_loss: 14.8545 - val_mae: 2.8625\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7157 - mae: 2.0984 - val_loss: 14.7661 - val_mae: 2.8538\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7108 - mae: 2.1063 - val_loss: 14.7793 - val_mae: 2.8659\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.6139 - mae: 2.0995 - val_loss: 14.8865 - val_mae: 2.8571\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5462 - mae: 2.0837 - val_loss: 14.6973 - val_mae: 2.8394\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.5450 - mae: 2.0913 - val_loss: 14.6576 - val_mae: 2.8458\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3919 - mae: 2.0740 - val_loss: 14.6109 - val_mae: 2.8299\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5103 - mae: 2.0742 - val_loss: 14.6171 - val_mae: 2.8256\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3439 - mae: 2.0573 - val_loss: 14.5384 - val_mae: 2.8379\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3448 - mae: 2.0625 - val_loss: 14.5054 - val_mae: 2.8292\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3992 - mae: 2.0729 - val_loss: 14.4495 - val_mae: 2.8400\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.1559 - mae: 2.0451 - val_loss: 14.5262 - val_mae: 2.8230\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.1843 - mae: 2.0308 - val_loss: 14.4062 - val_mae: 2.8011\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.0505 - mae: 2.0329 - val_loss: 14.4577 - val_mae: 2.8393\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9914 - mae: 2.0405 - val_loss: 14.4321 - val_mae: 2.8379\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8743 - mae: 2.0189 - val_loss: 14.4080 - val_mae: 2.8256\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.8222 - mae: 2.0046 - val_loss: 14.3304 - val_mae: 2.8076\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.7435 - mae: 1.9976 - val_loss: 14.3865 - val_mae: 2.8213\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6825 - mae: 1.9976 - val_loss: 14.3809 - val_mae: 2.8182\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.7078 - mae: 1.9943 - val_loss: 14.2947 - val_mae: 2.8093\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.5303 - mae: 1.9773 - val_loss: 14.2270 - val_mae: 2.7852\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5763 - mae: 1.9733 - val_loss: 14.1351 - val_mae: 2.7902\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4354 - mae: 1.9589 - val_loss: 14.1378 - val_mae: 2.7925\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3855 - mae: 1.9489 - val_loss: 14.1014 - val_mae: 2.7935\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3603 - mae: 1.9461 - val_loss: 14.0896 - val_mae: 2.7932\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.2902 - mae: 1.9483 - val_loss: 14.0943 - val_mae: 2.7952\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.2065 - mae: 1.9422 - val_loss: 14.0425 - val_mae: 2.7856\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.2426 - mae: 1.9359 - val_loss: 14.0411 - val_mae: 2.7784\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.0987 - mae: 1.9106 - val_loss: 13.9470 - val_mae: 2.7723\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.1348 - mae: 1.9276 - val_loss: 13.9381 - val_mae: 2.7594\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0394 - mae: 1.9114 - val_loss: 13.8652 - val_mae: 2.7481\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9608 - mae: 1.9019 - val_loss: 13.7851 - val_mae: 2.7491\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.9646 - mae: 1.9179 - val_loss: 13.6356 - val_mae: 2.7274\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8396 - mae: 1.8798 - val_loss: 13.7557 - val_mae: 2.7429\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.9421 - mae: 1.8823 - val_loss: 13.8189 - val_mae: 2.7353\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9191 - mae: 1.9051 - val_loss: 13.7263 - val_mae: 2.7346\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7731 - mae: 1.8914 - val_loss: 13.7044 - val_mae: 2.7266\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.6737 - mae: 1.8590 - val_loss: 13.6280 - val_mae: 2.7221\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5763 - mae: 1.8574 - val_loss: 13.7510 - val_mae: 2.7465\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5371 - mae: 1.8547 - val_loss: 13.7475 - val_mae: 2.7458\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.4784 - mae: 1.8388 - val_loss: 13.6987 - val_mae: 2.7352\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.4201 - mae: 1.8365 - val_loss: 13.7272 - val_mae: 2.7435\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.3795 - mae: 1.8317 - val_loss: 13.5740 - val_mae: 2.7180\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.3438 - mae: 1.8229 - val_loss: 13.5228 - val_mae: 2.7135\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2818 - mae: 1.8183 - val_loss: 13.6029 - val_mae: 2.7270\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.2363 - mae: 1.8097 - val_loss: 13.4838 - val_mae: 2.7122\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2198 - mae: 1.8042 - val_loss: 13.2955 - val_mae: 2.6858\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1421 - mae: 1.7964 - val_loss: 13.3806 - val_mae: 2.7053\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.1203 - mae: 1.7893 - val_loss: 13.4259 - val_mae: 2.7086\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.0321 - mae: 1.7778 - val_loss: 13.3758 - val_mae: 2.6957\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0070 - mae: 1.7718 - val_loss: 13.2926 - val_mae: 2.6806\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9674 - mae: 1.7664 - val_loss: 13.2353 - val_mae: 2.6871\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9001 - mae: 1.7559 - val_loss: 13.3649 - val_mae: 2.7075\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8358 - mae: 1.7457 - val_loss: 13.4011 - val_mae: 2.7085\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8480 - mae: 1.7455 - val_loss: 13.2355 - val_mae: 2.6766\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.7517 - mae: 1.7474 - val_loss: 13.3207 - val_mae: 2.6883\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7212 - mae: 1.7465 - val_loss: 13.2247 - val_mae: 2.6799\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6949 - mae: 1.7433 - val_loss: 13.2867 - val_mae: 2.6931\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.5898 - mae: 1.7147 - val_loss: 13.2470 - val_mae: 2.6764\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6025 - mae: 1.7122 - val_loss: 13.2289 - val_mae: 2.6675\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6006 - mae: 1.7381 - val_loss: 13.2685 - val_mae: 2.6722\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.5140 - mae: 1.7142 - val_loss: 13.1178 - val_mae: 2.6644\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.4204 - mae: 1.6933 - val_loss: 13.1186 - val_mae: 2.6591\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4293 - mae: 1.6954 - val_loss: 13.1371 - val_mae: 2.6671\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3686 - mae: 1.7008 - val_loss: 13.1554 - val_mae: 2.6766\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3082 - mae: 1.6858 - val_loss: 12.9546 - val_mae: 2.6487\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3121 - mae: 1.6698 - val_loss: 13.0214 - val_mae: 2.6488\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2427 - mae: 1.6719 - val_loss: 13.1071 - val_mae: 2.6557\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2039 - mae: 1.6738 - val_loss: 12.9860 - val_mae: 2.6314\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1918 - mae: 1.6625 - val_loss: 13.0751 - val_mae: 2.6576\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.2296 - mae: 1.6798 - val_loss: 13.0490 - val_mae: 2.6503\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.1426 - mae: 1.6464 - val_loss: 13.1501 - val_mae: 2.6642\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0071 - mae: 1.6359 - val_loss: 13.0623 - val_mae: 2.6505\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0555 - mae: 1.6451 - val_loss: 12.9660 - val_mae: 2.6279\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0438 - mae: 1.6458 - val_loss: 13.0211 - val_mae: 2.6363\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9462 - mae: 1.6288 - val_loss: 13.2322 - val_mae: 2.6553\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9532 - mae: 1.6221 - val_loss: 13.1507 - val_mae: 2.6505\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9238 - mae: 1.6339 - val_loss: 13.0741 - val_mae: 2.6462\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.8815 - mae: 1.6197 - val_loss: 12.8866 - val_mae: 2.6143\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.7984 - mae: 1.6059 - val_loss: 13.1125 - val_mae: 2.6485\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7861 - mae: 1.6122 - val_loss: 13.0986 - val_mae: 2.6462\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.7911 - mae: 1.6152 - val_loss: 13.1167 - val_mae: 2.6506\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7745 - mae: 1.5892 - val_loss: 13.0705 - val_mae: 2.6354\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7486 - mae: 1.5981 - val_loss: 12.9432 - val_mae: 2.6169\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6108 - mae: 1.5863 - val_loss: 12.9110 - val_mae: 2.6149\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6617 - mae: 1.5668 - val_loss: 12.9912 - val_mae: 2.6309\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.6299 - mae: 1.5831 - val_loss: 12.8695 - val_mae: 2.6005\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.5242 - mae: 1.5606 - val_loss: 12.9433 - val_mae: 2.6151\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.5067 - mae: 1.5507 - val_loss: 13.0186 - val_mae: 2.6170\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4968 - mae: 1.5625 - val_loss: 13.1547 - val_mae: 2.6354\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.4173 - mae: 1.5459 - val_loss: 13.1059 - val_mae: 2.6353\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4589 - mae: 1.5422 - val_loss: 12.9698 - val_mae: 2.6108\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4790 - mae: 1.5555 - val_loss: 12.9424 - val_mae: 2.6319\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4141 - mae: 1.5310 - val_loss: 12.8684 - val_mae: 2.6060\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3756 - mae: 1.5492 - val_loss: 12.8340 - val_mae: 2.5910\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.3037 - mae: 1.5325 - val_loss: 12.9233 - val_mae: 2.5976\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2893 - mae: 1.5282 - val_loss: 12.7545 - val_mae: 2.5834\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2299 - mae: 1.5134 - val_loss: 12.9539 - val_mae: 2.6178\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2373 - mae: 1.5145 - val_loss: 12.8231 - val_mae: 2.5877\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2026 - mae: 1.5132 - val_loss: 12.8210 - val_mae: 2.5846\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1678 - mae: 1.5042 - val_loss: 12.9253 - val_mae: 2.6019\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1755 - mae: 1.5245 - val_loss: 12.8056 - val_mae: 2.5798\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.1515 - mae: 1.4986 - val_loss: 12.7831 - val_mae: 2.5836\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.0972 - mae: 1.4979 - val_loss: 12.8431 - val_mae: 2.5825\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0690 - mae: 1.4887 - val_loss: 12.8349 - val_mae: 2.5881\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0593 - mae: 1.4816 - val_loss: 12.7952 - val_mae: 2.5773\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9826 - mae: 1.4707 - val_loss: 12.8769 - val_mae: 2.5894\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.0291 - mae: 1.4829 - val_loss: 12.8795 - val_mae: 2.5894\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0378 - mae: 1.4845 - val_loss: 12.8836 - val_mae: 2.5994\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9429 - mae: 1.4603 - val_loss: 12.7178 - val_mae: 2.5731\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9049 - mae: 1.4527 - val_loss: 12.7723 - val_mae: 2.5756\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9272 - mae: 1.4631 - val_loss: 12.7545 - val_mae: 2.5655\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8759 - mae: 1.4490 - val_loss: 12.8307 - val_mae: 2.5853\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8760 - mae: 1.4522 - val_loss: 12.6727 - val_mae: 2.5495\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9282 - mae: 1.4791 - val_loss: 12.8135 - val_mae: 2.5696\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9072 - mae: 1.4646 - val_loss: 12.6551 - val_mae: 2.5747\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.8108 - mae: 1.4400 - val_loss: 12.5578 - val_mae: 2.5307\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7857 - mae: 1.4441 - val_loss: 12.7910 - val_mae: 2.5783\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9504 - mae: 1.4723 - val_loss: 12.8364 - val_mae: 2.5780\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.8869 - mae: 1.4668 - val_loss: 12.8788 - val_mae: 2.5689\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.8818 - mae: 1.4484 - val_loss: 12.8255 - val_mae: 2.5875\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7353 - mae: 1.4259 - val_loss: 12.7140 - val_mae: 2.5572\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7105 - mae: 1.4381 - val_loss: 12.6996 - val_mae: 2.5558\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6685 - mae: 1.4231 - val_loss: 12.7361 - val_mae: 2.5576\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6686 - mae: 1.4203 - val_loss: 13.0254 - val_mae: 2.6114\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6336 - mae: 1.4018 - val_loss: 12.7584 - val_mae: 2.5602\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6204 - mae: 1.4078 - val_loss: 12.8076 - val_mae: 2.5757\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5964 - mae: 1.3985 - val_loss: 12.7490 - val_mae: 2.5614\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5384 - mae: 1.3818 - val_loss: 12.7088 - val_mae: 2.5419\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5221 - mae: 1.3944 - val_loss: 12.9385 - val_mae: 2.5718\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.5174 - mae: 1.3925 - val_loss: 12.8350 - val_mae: 2.5719\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5033 - mae: 1.3788 - val_loss: 12.8544 - val_mae: 2.5770\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.4870 - mae: 1.3854 - val_loss: 12.7976 - val_mae: 2.5578\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.4702 - mae: 1.3739 - val_loss: 12.7808 - val_mae: 2.5548\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.4797 - mae: 1.3779 - val_loss: 12.8498 - val_mae: 2.5549\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.4268 - mae: 1.3602 - val_loss: 12.7161 - val_mae: 2.5465\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.3996 - mae: 1.3596 - val_loss: 12.8166 - val_mae: 2.5537\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.3790 - mae: 1.3569 - val_loss: 12.6400 - val_mae: 2.5230\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3837 - mae: 1.3592 - val_loss: 12.6270 - val_mae: 2.5233\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3689 - mae: 1.3594 - val_loss: 12.6744 - val_mae: 2.5323\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3435 - mae: 1.3500 - val_loss: 12.7467 - val_mae: 2.5495\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3039 - mae: 1.3393 - val_loss: 12.6151 - val_mae: 2.5164\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.3081 - mae: 1.3374 - val_loss: 12.7073 - val_mae: 2.5373\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.3054 - mae: 1.3423 - val_loss: 12.7233 - val_mae: 2.5398\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3123 - mae: 1.3272 - val_loss: 12.6342 - val_mae: 2.5242\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2778 - mae: 1.3265 - val_loss: 12.8191 - val_mae: 2.5547\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.3099 - mae: 1.3548 - val_loss: 12.6833 - val_mae: 2.5190\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2404 - mae: 1.3256 - val_loss: 12.8267 - val_mae: 2.5560\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2617 - mae: 1.3286 - val_loss: 12.5761 - val_mae: 2.5196\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2436 - mae: 1.3318 - val_loss: 12.6609 - val_mae: 2.5083\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2935 - mae: 1.3308 - val_loss: 12.5711 - val_mae: 2.4963\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1950 - mae: 1.3186 - val_loss: 12.7974 - val_mae: 2.5261\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1788 - mae: 1.3113 - val_loss: 12.7636 - val_mae: 2.5247\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1399 - mae: 1.2974 - val_loss: 12.6356 - val_mae: 2.5104\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.1129 - mae: 1.2905 - val_loss: 12.7285 - val_mae: 2.5270\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.1596 - mae: 1.3028 - val_loss: 12.8026 - val_mae: 2.5291\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1426 - mae: 1.3121 - val_loss: 12.8486 - val_mae: 2.5335\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.1206 - mae: 1.2831 - val_loss: 12.8576 - val_mae: 2.5292\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.1030 - mae: 1.3008 - val_loss: 12.6951 - val_mae: 2.4992\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.0453 - mae: 1.2761 - val_loss: 12.8161 - val_mae: 2.5268\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.0378 - mae: 1.2761 - val_loss: 12.6833 - val_mae: 2.5006\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.0287 - mae: 1.2906 - val_loss: 12.9342 - val_mae: 2.5445\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.0472 - mae: 1.2844 - val_loss: 13.0596 - val_mae: 2.5467\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.0154 - mae: 1.2800 - val_loss: 12.8069 - val_mae: 2.5097\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.0633 - mae: 1.2787 - val_loss: 12.6721 - val_mae: 2.4846\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.0304 - mae: 1.2903 - val_loss: 13.2762 - val_mae: 2.5750\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.0908 - mae: 1.3053 - val_loss: 12.8396 - val_mae: 2.5166\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9571 - mae: 1.2629 - val_loss: 12.8617 - val_mae: 2.5185\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.9259 - mae: 1.2472 - val_loss: 12.7856 - val_mae: 2.5104\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9191 - mae: 1.2440 - val_loss: 12.7807 - val_mae: 2.4940\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9439 - mae: 1.2715 - val_loss: 13.1466 - val_mae: 2.5549\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9074 - mae: 1.2480 - val_loss: 12.9951 - val_mae: 2.5279\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.9089 - mae: 1.2414 - val_loss: 12.9386 - val_mae: 2.5152\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8909 - mae: 1.2469 - val_loss: 12.8251 - val_mae: 2.5078\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8908 - mae: 1.2371 - val_loss: 12.7919 - val_mae: 2.4949\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8651 - mae: 1.2414 - val_loss: 12.8863 - val_mae: 2.4999\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.8402 - mae: 1.2339 - val_loss: 12.8300 - val_mae: 2.5050\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.8374 - mae: 1.2376 - val_loss: 13.0241 - val_mae: 2.5361\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8938 - mae: 1.2439 - val_loss: 12.8603 - val_mae: 2.4934\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.8052 - mae: 1.2237 - val_loss: 12.8786 - val_mae: 2.4893\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8367 - mae: 1.2371 - val_loss: 12.9110 - val_mae: 2.4981\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8214 - mae: 1.2268 - val_loss: 13.0197 - val_mae: 2.5217\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.7877 - mae: 1.2207 - val_loss: 13.0154 - val_mae: 2.5177\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7558 - mae: 1.2106 - val_loss: 12.8504 - val_mae: 2.4943\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7382 - mae: 1.1995 - val_loss: 12.8228 - val_mae: 2.4953\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7310 - mae: 1.1954 - val_loss: 12.7956 - val_mae: 2.4799\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7407 - mae: 1.2094 - val_loss: 13.0706 - val_mae: 2.5234\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7769 - mae: 1.2087 - val_loss: 12.8135 - val_mae: 2.4614\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.9354 - mae: 1.2744 - val_loss: 13.0072 - val_mae: 2.4974\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.7452 - mae: 1.2053 - val_loss: 12.9690 - val_mae: 2.4935\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.7899 - mae: 1.2384 - val_loss: 12.8574 - val_mae: 2.4757\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6877 - mae: 1.1846 - val_loss: 12.7657 - val_mae: 2.4799\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6681 - mae: 1.1822 - val_loss: 13.0027 - val_mae: 2.5013\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6563 - mae: 1.1866 - val_loss: 12.9809 - val_mae: 2.5112\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6217 - mae: 1.1776 - val_loss: 13.0022 - val_mae: 2.4892\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6715 - mae: 1.1812 - val_loss: 12.9383 - val_mae: 2.4933\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5991 - mae: 1.1700 - val_loss: 12.9808 - val_mae: 2.4881\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.6316 - mae: 1.1852 - val_loss: 12.9868 - val_mae: 2.4766\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6025 - mae: 1.1604 - val_loss: 12.9309 - val_mae: 2.4736\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6013 - mae: 1.1678 - val_loss: 12.8261 - val_mae: 2.4529\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5964 - mae: 1.1619 - val_loss: 13.0662 - val_mae: 2.4863\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.5745 - mae: 1.1675 - val_loss: 12.9837 - val_mae: 2.4833\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5854 - mae: 1.1579 - val_loss: 12.9917 - val_mae: 2.4795\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6312 - mae: 1.1956 - val_loss: 12.8912 - val_mae: 2.4730\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5411 - mae: 1.1561 - val_loss: 13.0399 - val_mae: 2.4982\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5522 - mae: 1.1550 - val_loss: 13.1154 - val_mae: 2.4887\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5563 - mae: 1.1685 - val_loss: 12.9635 - val_mae: 2.4745\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 8.6075 - mae: 2.0721\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 19ms/step - loss: 504.0157 - mae: 20.4222 - val_loss: 580.2334 - val_mae: 22.0451\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 465.9807 - mae: 19.4835 - val_loss: 533.5544 - val_mae: 21.0288\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 426.9404 - mae: 18.4749 - val_loss: 483.9670 - val_mae: 19.9003\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 385.0720 - mae: 17.3623 - val_loss: 431.3754 - val_mae: 18.6349\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 339.8931 - mae: 16.1071 - val_loss: 373.3817 - val_mae: 17.1696\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 292.3495 - mae: 14.7307 - val_loss: 310.3193 - val_mae: 15.4311\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 239.4177 - mae: 13.1335 - val_loss: 248.2875 - val_mae: 13.4815\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 191.8001 - mae: 11.4495 - val_loss: 188.9408 - val_mae: 11.3450\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 145.8232 - mae: 9.8104 - val_loss: 141.8581 - val_mae: 9.3707\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 110.4192 - mae: 8.3915 - val_loss: 108.7621 - val_mae: 7.9823\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 85.5098 - mae: 7.2852 - val_loss: 87.8815 - val_mae: 7.0827\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 68.9239 - mae: 6.4545 - val_loss: 73.4798 - val_mae: 6.4622\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 56.2241 - mae: 5.7255 - val_loss: 62.6131 - val_mae: 5.9111\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 46.0085 - mae: 5.1121 - val_loss: 53.9536 - val_mae: 5.3913\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 38.8525 - mae: 4.6755 - val_loss: 46.5072 - val_mae: 4.8701\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 33.2467 - mae: 4.3055 - val_loss: 41.5298 - val_mae: 4.5418\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29.1861 - mae: 4.0442 - val_loss: 38.1314 - val_mae: 4.2819\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 26.5981 - mae: 3.8400 - val_loss: 35.7041 - val_mae: 4.0932\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 24.7045 - mae: 3.7131 - val_loss: 34.1324 - val_mae: 3.9717\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 23.4290 - mae: 3.6012 - val_loss: 32.8780 - val_mae: 3.8678\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 22.5579 - mae: 3.5211 - val_loss: 31.7904 - val_mae: 3.7836\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 21.6638 - mae: 3.4399 - val_loss: 30.8989 - val_mae: 3.7054\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 21.0863 - mae: 3.3857 - val_loss: 30.0518 - val_mae: 3.6477\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 20.3679 - mae: 3.3196 - val_loss: 29.4998 - val_mae: 3.5910\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 19.8676 - mae: 3.2677 - val_loss: 28.9412 - val_mae: 3.5426\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 19.3771 - mae: 3.2218 - val_loss: 28.4240 - val_mae: 3.4968\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 18.9258 - mae: 3.1808 - val_loss: 27.8667 - val_mae: 3.4429\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 18.4630 - mae: 3.1474 - val_loss: 27.3692 - val_mae: 3.4176\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 18.0454 - mae: 3.1184 - val_loss: 26.8179 - val_mae: 3.3683\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 17.6315 - mae: 3.0786 - val_loss: 26.5409 - val_mae: 3.3400\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 17.2855 - mae: 3.0408 - val_loss: 26.2173 - val_mae: 3.3320\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 16.8841 - mae: 3.0066 - val_loss: 25.7791 - val_mae: 3.2971\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 16.5776 - mae: 2.9754 - val_loss: 25.4859 - val_mae: 3.2685\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.2575 - mae: 2.9469 - val_loss: 25.1041 - val_mae: 3.2334\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.9780 - mae: 2.9142 - val_loss: 24.9474 - val_mae: 3.2241\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.6839 - mae: 2.8828 - val_loss: 24.6222 - val_mae: 3.2055\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.3743 - mae: 2.8507 - val_loss: 24.4720 - val_mae: 3.1800\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.2169 - mae: 2.8338 - val_loss: 24.2036 - val_mae: 3.1660\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.8910 - mae: 2.7991 - val_loss: 24.0396 - val_mae: 3.1471\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.6330 - mae: 2.7689 - val_loss: 23.7154 - val_mae: 3.1121\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.4170 - mae: 2.7539 - val_loss: 23.4252 - val_mae: 3.0880\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.2033 - mae: 2.7403 - val_loss: 23.2050 - val_mae: 3.0801\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.9596 - mae: 2.7118 - val_loss: 23.1023 - val_mae: 3.0646\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.7962 - mae: 2.6871 - val_loss: 23.0285 - val_mae: 3.0494\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.5969 - mae: 2.6588 - val_loss: 22.8500 - val_mae: 3.0380\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.3533 - mae: 2.6352 - val_loss: 22.5755 - val_mae: 3.0145\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.1467 - mae: 2.6213 - val_loss: 22.3907 - val_mae: 3.0079\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.0156 - mae: 2.6159 - val_loss: 22.2843 - val_mae: 3.0045\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.8599 - mae: 2.6049 - val_loss: 22.0425 - val_mae: 2.9727\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.6605 - mae: 2.5793 - val_loss: 21.9837 - val_mae: 2.9666\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.4867 - mae: 2.5578 - val_loss: 21.8844 - val_mae: 2.9610\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.3446 - mae: 2.5516 - val_loss: 21.7324 - val_mae: 2.9525\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.1787 - mae: 2.5383 - val_loss: 21.5663 - val_mae: 2.9324\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.0200 - mae: 2.5156 - val_loss: 21.4699 - val_mae: 2.9100\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.8822 - mae: 2.4877 - val_loss: 21.3975 - val_mae: 2.9078\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.7260 - mae: 2.4748 - val_loss: 21.3129 - val_mae: 2.8997\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.5923 - mae: 2.4658 - val_loss: 21.2205 - val_mae: 2.8891\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.4630 - mae: 2.4543 - val_loss: 21.1603 - val_mae: 2.8881\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.3651 - mae: 2.4479 - val_loss: 21.0052 - val_mae: 2.8649\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.3353 - mae: 2.4488 - val_loss: 20.8240 - val_mae: 2.8506\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.1154 - mae: 2.4260 - val_loss: 20.8320 - val_mae: 2.8542\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.1040 - mae: 2.4342 - val_loss: 20.8057 - val_mae: 2.8638\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.8556 - mae: 2.3961 - val_loss: 20.7322 - val_mae: 2.8582\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.8004 - mae: 2.3725 - val_loss: 20.5780 - val_mae: 2.8425\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.7238 - mae: 2.3582 - val_loss: 20.5130 - val_mae: 2.8378\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.6276 - mae: 2.3585 - val_loss: 20.4146 - val_mae: 2.8357\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.5420 - mae: 2.3608 - val_loss: 20.3259 - val_mae: 2.8194\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.4380 - mae: 2.3554 - val_loss: 20.2847 - val_mae: 2.8180\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.3375 - mae: 2.3379 - val_loss: 20.3251 - val_mae: 2.8191\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.2865 - mae: 2.3222 - val_loss: 20.1992 - val_mae: 2.7983\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.1579 - mae: 2.3059 - val_loss: 20.2531 - val_mae: 2.8068\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.0939 - mae: 2.2999 - val_loss: 20.3006 - val_mae: 2.8264\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.0577 - mae: 2.2959 - val_loss: 20.3625 - val_mae: 2.8251\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.0331 - mae: 2.3039 - val_loss: 20.2214 - val_mae: 2.7904\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.9002 - mae: 2.2805 - val_loss: 20.3410 - val_mae: 2.8247\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.8376 - mae: 2.2642 - val_loss: 20.2695 - val_mae: 2.8226\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6848 - mae: 2.2551 - val_loss: 19.9956 - val_mae: 2.7779\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.7407 - mae: 2.2480 - val_loss: 19.9926 - val_mae: 2.7869\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6697 - mae: 2.2301 - val_loss: 20.0503 - val_mae: 2.8024\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.5144 - mae: 2.2239 - val_loss: 19.9120 - val_mae: 2.7915\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.4724 - mae: 2.2319 - val_loss: 19.9365 - val_mae: 2.7938\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4273 - mae: 2.2231 - val_loss: 19.9179 - val_mae: 2.7949\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.3582 - mae: 2.2112 - val_loss: 19.8806 - val_mae: 2.7909\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.2955 - mae: 2.1981 - val_loss: 19.7219 - val_mae: 2.7768\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.2687 - mae: 2.1897 - val_loss: 19.6765 - val_mae: 2.7674\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2388 - mae: 2.1900 - val_loss: 19.6369 - val_mae: 2.7677\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1642 - mae: 2.1868 - val_loss: 19.6928 - val_mae: 2.7831\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1224 - mae: 2.1714 - val_loss: 19.5475 - val_mae: 2.7665\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0463 - mae: 2.1616 - val_loss: 19.6434 - val_mae: 2.7722\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.0280 - mae: 2.1624 - val_loss: 19.7329 - val_mae: 2.7875\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.9601 - mae: 2.1557 - val_loss: 19.6047 - val_mae: 2.7747\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9087 - mae: 2.1430 - val_loss: 19.5264 - val_mae: 2.7779\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8946 - mae: 2.1410 - val_loss: 19.5912 - val_mae: 2.7835\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8506 - mae: 2.1375 - val_loss: 19.3965 - val_mae: 2.7539\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7795 - mae: 2.1309 - val_loss: 19.4230 - val_mae: 2.7698\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7412 - mae: 2.1191 - val_loss: 19.3813 - val_mae: 2.7679\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7611 - mae: 2.1126 - val_loss: 19.4406 - val_mae: 2.7939\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6471 - mae: 2.0972 - val_loss: 19.2456 - val_mae: 2.7525\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5939 - mae: 2.1007 - val_loss: 19.1889 - val_mae: 2.7388\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5929 - mae: 2.1066 - val_loss: 19.2229 - val_mae: 2.7543\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.4912 - mae: 2.0882 - val_loss: 19.1705 - val_mae: 2.7490\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4751 - mae: 2.0867 - val_loss: 19.1981 - val_mae: 2.7603\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.4408 - mae: 2.0762 - val_loss: 19.1543 - val_mae: 2.7484\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3515 - mae: 2.0697 - val_loss: 19.0146 - val_mae: 2.7264\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3540 - mae: 2.0633 - val_loss: 19.0480 - val_mae: 2.7330\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3098 - mae: 2.0486 - val_loss: 19.2494 - val_mae: 2.7707\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3024 - mae: 2.0426 - val_loss: 19.1113 - val_mae: 2.7488\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2250 - mae: 2.0461 - val_loss: 19.1121 - val_mae: 2.7568\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2527 - mae: 2.0750 - val_loss: 18.9395 - val_mae: 2.7425\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1282 - mae: 2.0451 - val_loss: 18.8643 - val_mae: 2.7345\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1012 - mae: 2.0182 - val_loss: 18.9816 - val_mae: 2.7654\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.0911 - mae: 2.0271 - val_loss: 18.7530 - val_mae: 2.7330\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.0366 - mae: 2.0242 - val_loss: 18.7885 - val_mae: 2.7218\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9784 - mae: 2.0174 - val_loss: 18.8058 - val_mae: 2.7463\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.0306 - mae: 2.0209 - val_loss: 18.9182 - val_mae: 2.7563\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.9756 - mae: 2.0101 - val_loss: 18.7805 - val_mae: 2.7194\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.8972 - mae: 1.9969 - val_loss: 18.7884 - val_mae: 2.7276\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8394 - mae: 1.9922 - val_loss: 18.6766 - val_mae: 2.7117\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8487 - mae: 1.9889 - val_loss: 18.6252 - val_mae: 2.7138\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8368 - mae: 1.9883 - val_loss: 18.5918 - val_mae: 2.7164\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.8060 - mae: 1.9840 - val_loss: 18.4422 - val_mae: 2.6948\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.7549 - mae: 1.9713 - val_loss: 18.5487 - val_mae: 2.7309\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7266 - mae: 1.9761 - val_loss: 18.5457 - val_mae: 2.7363\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7022 - mae: 1.9825 - val_loss: 18.5173 - val_mae: 2.7162\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7053 - mae: 1.9754 - val_loss: 18.4005 - val_mae: 2.6845\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.6685 - mae: 1.9575 - val_loss: 18.4634 - val_mae: 2.7168\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.6141 - mae: 1.9510 - val_loss: 18.3461 - val_mae: 2.6971\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.6106 - mae: 1.9576 - val_loss: 18.3403 - val_mae: 2.6979\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6147 - mae: 1.9504 - val_loss: 18.5885 - val_mae: 2.7412\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6780 - mae: 1.9629 - val_loss: 18.5884 - val_mae: 2.7508\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5820 - mae: 1.9539 - val_loss: 18.1462 - val_mae: 2.6882\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.5046 - mae: 1.9324 - val_loss: 18.1975 - val_mae: 2.6977\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.5094 - mae: 1.9376 - val_loss: 18.3515 - val_mae: 2.7281\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4380 - mae: 1.9225 - val_loss: 18.1853 - val_mae: 2.6804\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4197 - mae: 1.9142 - val_loss: 18.1824 - val_mae: 2.6901\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4760 - mae: 1.9441 - val_loss: 18.3489 - val_mae: 2.7389\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3375 - mae: 1.9271 - val_loss: 18.1451 - val_mae: 2.7073\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.3433 - mae: 1.9181 - val_loss: 18.0202 - val_mae: 2.6751\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.3167 - mae: 1.9000 - val_loss: 18.1696 - val_mae: 2.6993\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.2599 - mae: 1.8944 - val_loss: 18.2151 - val_mae: 2.7101\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.2758 - mae: 1.9123 - val_loss: 18.0326 - val_mae: 2.6860\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2841 - mae: 1.9178 - val_loss: 18.1785 - val_mae: 2.7089\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.2020 - mae: 1.8991 - val_loss: 18.0107 - val_mae: 2.6860\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.1944 - mae: 1.8911 - val_loss: 17.8974 - val_mae: 2.6805\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.1673 - mae: 1.8860 - val_loss: 18.0890 - val_mae: 2.7012\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.1497 - mae: 1.8859 - val_loss: 17.9125 - val_mae: 2.6963\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1670 - mae: 1.8835 - val_loss: 17.8945 - val_mae: 2.6750\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.1668 - mae: 1.8969 - val_loss: 17.8795 - val_mae: 2.6913\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.0726 - mae: 1.8734 - val_loss: 17.9914 - val_mae: 2.7092\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0739 - mae: 1.8705 - val_loss: 17.8192 - val_mae: 2.6703\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.0359 - mae: 1.8704 - val_loss: 17.9051 - val_mae: 2.6948\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.9770 - mae: 1.8682 - val_loss: 17.8083 - val_mae: 2.6777\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.9422 - mae: 1.8577 - val_loss: 17.7556 - val_mae: 2.6702\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9280 - mae: 1.8573 - val_loss: 17.9114 - val_mae: 2.7017\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9342 - mae: 1.8572 - val_loss: 17.7662 - val_mae: 2.6749\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.9440 - mae: 1.8372 - val_loss: 17.9016 - val_mae: 2.6882\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8767 - mae: 1.8367 - val_loss: 17.8534 - val_mae: 2.6926\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8417 - mae: 1.8433 - val_loss: 17.8071 - val_mae: 2.6842\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.8330 - mae: 1.8420 - val_loss: 17.8577 - val_mae: 2.6969\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.8045 - mae: 1.8261 - val_loss: 17.7015 - val_mae: 2.6734\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7901 - mae: 1.8198 - val_loss: 17.7368 - val_mae: 2.6782\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7506 - mae: 1.8215 - val_loss: 17.7283 - val_mae: 2.6875\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7580 - mae: 1.8335 - val_loss: 17.7532 - val_mae: 2.6926\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7468 - mae: 1.8288 - val_loss: 17.7228 - val_mae: 2.6795\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.6963 - mae: 1.8176 - val_loss: 17.5971 - val_mae: 2.6735\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.7010 - mae: 1.8187 - val_loss: 17.6615 - val_mae: 2.6677\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.6484 - mae: 1.8059 - val_loss: 17.7587 - val_mae: 2.6956\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.6588 - mae: 1.8178 - val_loss: 17.8361 - val_mae: 2.7056\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.6431 - mae: 1.8218 - val_loss: 17.6480 - val_mae: 2.6769\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.6261 - mae: 1.8047 - val_loss: 17.6722 - val_mae: 2.6825\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5714 - mae: 1.8023 - val_loss: 17.6233 - val_mae: 2.6800\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.5819 - mae: 1.8080 - val_loss: 17.5878 - val_mae: 2.6785\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5381 - mae: 1.7979 - val_loss: 17.5407 - val_mae: 2.6656\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.5637 - mae: 1.7930 - val_loss: 17.5086 - val_mae: 2.6617\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4931 - mae: 1.7968 - val_loss: 17.6697 - val_mae: 2.6931\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4982 - mae: 1.7918 - val_loss: 17.6697 - val_mae: 2.6910\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4463 - mae: 1.7979 - val_loss: 17.6227 - val_mae: 2.7083\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.4730 - mae: 1.8001 - val_loss: 17.5727 - val_mae: 2.6885\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4916 - mae: 1.7788 - val_loss: 17.4233 - val_mae: 2.6678\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.4516 - mae: 1.7858 - val_loss: 17.7446 - val_mae: 2.7132\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4598 - mae: 1.8051 - val_loss: 17.5610 - val_mae: 2.6987\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.3612 - mae: 1.7804 - val_loss: 17.4772 - val_mae: 2.6801\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.3743 - mae: 1.7625 - val_loss: 17.5340 - val_mae: 2.6798\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.3326 - mae: 1.7720 - val_loss: 17.4533 - val_mae: 2.6935\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.3279 - mae: 1.7760 - val_loss: 17.5471 - val_mae: 2.6913\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2723 - mae: 1.7679 - val_loss: 17.4335 - val_mae: 2.6814\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.3841 - mae: 1.7645 - val_loss: 17.5012 - val_mae: 2.6740\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.4311 - mae: 1.7689 - val_loss: 17.4766 - val_mae: 2.7190\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.2645 - mae: 1.7755 - val_loss: 17.3172 - val_mae: 2.6709\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2287 - mae: 1.7382 - val_loss: 17.4892 - val_mae: 2.6703\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2850 - mae: 1.7562 - val_loss: 17.3933 - val_mae: 2.6877\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1620 - mae: 1.7433 - val_loss: 17.3820 - val_mae: 2.6889\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.1461 - mae: 1.7270 - val_loss: 17.2762 - val_mae: 2.6686\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.1557 - mae: 1.7597 - val_loss: 17.4461 - val_mae: 2.7073\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1048 - mae: 1.7429 - val_loss: 17.4540 - val_mae: 2.6968\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1148 - mae: 1.7327 - val_loss: 17.3089 - val_mae: 2.6743\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0650 - mae: 1.7244 - val_loss: 17.3626 - val_mae: 2.6947\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0727 - mae: 1.7223 - val_loss: 17.1682 - val_mae: 2.6685\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0149 - mae: 1.7170 - val_loss: 17.3023 - val_mae: 2.6896\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0165 - mae: 1.7111 - val_loss: 17.2744 - val_mae: 2.6892\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9881 - mae: 1.7130 - val_loss: 17.1265 - val_mae: 2.6818\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0153 - mae: 1.7279 - val_loss: 17.2112 - val_mae: 2.6709\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9184 - mae: 1.7015 - val_loss: 17.1361 - val_mae: 2.6600\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9507 - mae: 1.6981 - val_loss: 17.1066 - val_mae: 2.6560\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9157 - mae: 1.6954 - val_loss: 17.0578 - val_mae: 2.6619\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9405 - mae: 1.7149 - val_loss: 17.0622 - val_mae: 2.6726\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9731 - mae: 1.7055 - val_loss: 17.3026 - val_mae: 2.6882\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9747 - mae: 1.7046 - val_loss: 16.9808 - val_mae: 2.6505\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8309 - mae: 1.6963 - val_loss: 17.1922 - val_mae: 2.6802\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8287 - mae: 1.6874 - val_loss: 17.2236 - val_mae: 2.6680\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8274 - mae: 1.6734 - val_loss: 17.1450 - val_mae: 2.6591\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7956 - mae: 1.6724 - val_loss: 17.1052 - val_mae: 2.6619\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7729 - mae: 1.6839 - val_loss: 16.9941 - val_mae: 2.6714\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7917 - mae: 1.6954 - val_loss: 17.0159 - val_mae: 2.6666\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8285 - mae: 1.6844 - val_loss: 16.9453 - val_mae: 2.6355\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8491 - mae: 1.7048 - val_loss: 17.1697 - val_mae: 2.6896\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8345 - mae: 1.7148 - val_loss: 16.8655 - val_mae: 2.6564\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6994 - mae: 1.6631 - val_loss: 16.9743 - val_mae: 2.6625\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6656 - mae: 1.6663 - val_loss: 16.9648 - val_mae: 2.6800\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5944 - mae: 1.6623 - val_loss: 16.9202 - val_mae: 2.6587\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6062 - mae: 1.6549 - val_loss: 16.9289 - val_mae: 2.6563\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5725 - mae: 1.6406 - val_loss: 16.9183 - val_mae: 2.6499\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6094 - mae: 1.6541 - val_loss: 17.1974 - val_mae: 2.6923\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.5456 - mae: 1.6530 - val_loss: 16.8389 - val_mae: 2.6669\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.4780 - mae: 1.6434 - val_loss: 16.8401 - val_mae: 2.6420\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5055 - mae: 1.6299 - val_loss: 16.9215 - val_mae: 2.6610\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4613 - mae: 1.6428 - val_loss: 16.8155 - val_mae: 2.6541\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4317 - mae: 1.6332 - val_loss: 16.8576 - val_mae: 2.6413\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4596 - mae: 1.6257 - val_loss: 16.8456 - val_mae: 2.6414\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4009 - mae: 1.6267 - val_loss: 16.9810 - val_mae: 2.7014\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4741 - mae: 1.6637 - val_loss: 16.8513 - val_mae: 2.6673\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.4247 - mae: 1.6255 - val_loss: 16.8979 - val_mae: 2.6406\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3594 - mae: 1.6075 - val_loss: 16.6028 - val_mae: 2.6261\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3945 - mae: 1.6501 - val_loss: 16.6737 - val_mae: 2.6839\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2964 - mae: 1.6220 - val_loss: 16.7848 - val_mae: 2.6572\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3415 - mae: 1.6099 - val_loss: 16.7403 - val_mae: 2.6326\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2707 - mae: 1.6097 - val_loss: 16.7329 - val_mae: 2.6706\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2557 - mae: 1.6182 - val_loss: 16.6836 - val_mae: 2.6559\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2351 - mae: 1.5922 - val_loss: 16.6100 - val_mae: 2.6342\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.1741 - mae: 1.5854 - val_loss: 16.5519 - val_mae: 2.6440\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1836 - mae: 1.5851 - val_loss: 16.6435 - val_mae: 2.6501\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.1293 - mae: 1.5861 - val_loss: 16.6574 - val_mae: 2.6693\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1123 - mae: 1.5834 - val_loss: 16.6620 - val_mae: 2.6594\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1333 - mae: 1.5817 - val_loss: 16.5360 - val_mae: 2.6334\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1188 - mae: 1.5919 - val_loss: 16.4754 - val_mae: 2.6602\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0403 - mae: 1.5729 - val_loss: 16.6701 - val_mae: 2.6643\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0668 - mae: 1.5611 - val_loss: 16.5956 - val_mae: 2.6390\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0016 - mae: 1.5683 - val_loss: 16.5643 - val_mae: 2.6605\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9996 - mae: 1.5742 - val_loss: 16.4509 - val_mae: 2.6409\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9898 - mae: 1.5445 - val_loss: 16.4441 - val_mae: 2.6140\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9772 - mae: 1.5553 - val_loss: 16.4689 - val_mae: 2.6603\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9442 - mae: 1.5439 - val_loss: 16.4300 - val_mae: 2.6243\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9222 - mae: 1.5398 - val_loss: 16.5067 - val_mae: 2.6535\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0122 - mae: 1.5794 - val_loss: 16.5251 - val_mae: 2.6789\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8423 - mae: 1.5437 - val_loss: 16.4344 - val_mae: 2.6179\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.8475 - mae: 1.5241 - val_loss: 16.4748 - val_mae: 2.6388\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.8506 - mae: 1.5181 - val_loss: 16.4413 - val_mae: 2.6445\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7693 - mae: 1.5218 - val_loss: 16.4540 - val_mae: 2.6775\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7639 - mae: 1.5251 - val_loss: 16.4596 - val_mae: 2.6287\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7174 - mae: 1.4997 - val_loss: 16.3072 - val_mae: 2.6122\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6956 - mae: 1.4937 - val_loss: 16.3026 - val_mae: 2.6333\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6647 - mae: 1.4971 - val_loss: 16.3691 - val_mae: 2.6383\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6896 - mae: 1.4872 - val_loss: 16.4496 - val_mae: 2.6270\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.8846 - mae: 1.5383 - val_loss: 16.6332 - val_mae: 2.7085\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5978 - mae: 1.5001 - val_loss: 16.4685 - val_mae: 2.6188\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7024 - mae: 1.4778 - val_loss: 16.3192 - val_mae: 2.6276\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5408 - mae: 1.4743 - val_loss: 16.3309 - val_mae: 2.6665\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5487 - mae: 1.4962 - val_loss: 16.2500 - val_mae: 2.6439\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5412 - mae: 1.4729 - val_loss: 16.3604 - val_mae: 2.6343\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4951 - mae: 1.4679 - val_loss: 16.3267 - val_mae: 2.6474\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4801 - mae: 1.4768 - val_loss: 16.3275 - val_mae: 2.6574\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4894 - mae: 1.4815 - val_loss: 16.2700 - val_mae: 2.6489\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4746 - mae: 1.4435 - val_loss: 16.2586 - val_mae: 2.6214\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3815 - mae: 1.4537 - val_loss: 16.3039 - val_mae: 2.6683\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3790 - mae: 1.4604 - val_loss: 16.2494 - val_mae: 2.6398\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.3730 - mae: 1.4363 - val_loss: 16.1227 - val_mae: 2.6241\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3748 - mae: 1.4495 - val_loss: 16.2078 - val_mae: 2.6529\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3103 - mae: 1.4352 - val_loss: 16.2061 - val_mae: 2.6281\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3830 - mae: 1.4430 - val_loss: 16.2928 - val_mae: 2.6541\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2992 - mae: 1.4123 - val_loss: 16.1426 - val_mae: 2.6230\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2526 - mae: 1.4167 - val_loss: 16.1364 - val_mae: 2.6510\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2141 - mae: 1.4190 - val_loss: 16.0666 - val_mae: 2.6349\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2465 - mae: 1.4163 - val_loss: 15.9538 - val_mae: 2.6335\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1643 - mae: 1.4070 - val_loss: 16.0993 - val_mae: 2.6501\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1262 - mae: 1.4034 - val_loss: 16.1382 - val_mae: 2.6298\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.1111 - mae: 1.3960 - val_loss: 16.0386 - val_mae: 2.6358\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0923 - mae: 1.3934 - val_loss: 15.9479 - val_mae: 2.6530\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0564 - mae: 1.3872 - val_loss: 15.9341 - val_mae: 2.6285\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0436 - mae: 1.3746 - val_loss: 15.9593 - val_mae: 2.6298\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0368 - mae: 1.3798 - val_loss: 15.9376 - val_mae: 2.6366\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1595 - mae: 1.4215 - val_loss: 16.1497 - val_mae: 2.6718\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0106 - mae: 1.3755 - val_loss: 15.9859 - val_mae: 2.6327\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9959 - mae: 1.3620 - val_loss: 15.8672 - val_mae: 2.6380\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9788 - mae: 1.3993 - val_loss: 15.8436 - val_mae: 2.6622\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0119 - mae: 1.3907 - val_loss: 15.8293 - val_mae: 2.6295\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9262 - mae: 1.3406 - val_loss: 15.6177 - val_mae: 2.6079\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8793 - mae: 1.3570 - val_loss: 15.7133 - val_mae: 2.6352\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8657 - mae: 1.3689 - val_loss: 15.7514 - val_mae: 2.6266\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8466 - mae: 1.3626 - val_loss: 15.7682 - val_mae: 2.6238\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8507 - mae: 1.3416 - val_loss: 15.6511 - val_mae: 2.6060\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 7.9334 - mae: 2.0351\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 18ms/step - loss: 601.2042 - mae: 22.6710 - val_loss: 495.7466 - val_mae: 20.4831\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 578.3529 - mae: 22.1718 - val_loss: 474.9984 - val_mae: 19.9980\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 554.1250 - mae: 21.6505 - val_loss: 451.9821 - val_mae: 19.4422\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 525.7467 - mae: 21.0161 - val_loss: 423.7576 - val_mae: 18.7465\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 490.6476 - mae: 20.2131 - val_loss: 388.8117 - val_mae: 17.8587\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 447.1747 - mae: 19.1795 - val_loss: 346.7267 - val_mae: 16.7301\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 393.8944 - mae: 17.8566 - val_loss: 297.0475 - val_mae: 15.3022\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 331.4995 - mae: 16.1579 - val_loss: 241.0393 - val_mae: 13.5191\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 264.0461 - mae: 14.0361 - val_loss: 185.9996 - val_mae: 11.5108\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 200.7535 - mae: 11.8064 - val_loss: 138.4976 - val_mae: 9.5454\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 147.5979 - mae: 9.6577 - val_loss: 103.7483 - val_mae: 8.0135\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 112.0801 - mae: 8.0763 - val_loss: 81.8401 - val_mae: 7.0558\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 87.7560 - mae: 7.0274 - val_loss: 68.7845 - val_mae: 6.4980\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 73.1329 - mae: 6.2444 - val_loss: 59.2773 - val_mae: 6.0617\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 62.0101 - mae: 5.6733 - val_loss: 51.3635 - val_mae: 5.6282\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 53.3595 - mae: 5.2109 - val_loss: 44.5681 - val_mae: 5.2088\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 46.3788 - mae: 4.8203 - val_loss: 39.5387 - val_mae: 4.8650\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 41.0968 - mae: 4.5196 - val_loss: 35.7338 - val_mae: 4.5932\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 37.0911 - mae: 4.2734 - val_loss: 32.7202 - val_mae: 4.3611\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 34.1658 - mae: 4.0824 - val_loss: 30.6943 - val_mae: 4.2153\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 32.3189 - mae: 3.9617 - val_loss: 29.1451 - val_mae: 4.1028\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 30.7075 - mae: 3.8661 - val_loss: 27.8164 - val_mae: 3.9850\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 29.4345 - mae: 3.7855 - val_loss: 26.9053 - val_mae: 3.9020\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 28.5604 - mae: 3.7365 - val_loss: 26.0512 - val_mae: 3.8242\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 27.6934 - mae: 3.6850 - val_loss: 25.5242 - val_mae: 3.7910\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 26.9557 - mae: 3.6426 - val_loss: 25.0902 - val_mae: 3.7712\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26.3162 - mae: 3.6020 - val_loss: 24.5413 - val_mae: 3.7269\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 25.6833 - mae: 3.5542 - val_loss: 23.9175 - val_mae: 3.6724\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 25.1443 - mae: 3.5095 - val_loss: 23.4342 - val_mae: 3.6345\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 24.5067 - mae: 3.4706 - val_loss: 23.1391 - val_mae: 3.6041\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 24.0078 - mae: 3.4323 - val_loss: 22.7577 - val_mae: 3.5719\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 23.4900 - mae: 3.4012 - val_loss: 22.3550 - val_mae: 3.5413\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 22.9970 - mae: 3.3647 - val_loss: 22.0187 - val_mae: 3.5040\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 22.5002 - mae: 3.3199 - val_loss: 21.7747 - val_mae: 3.4725\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 22.0629 - mae: 3.2815 - val_loss: 21.2859 - val_mae: 3.4226\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 21.7473 - mae: 3.2580 - val_loss: 21.2634 - val_mae: 3.4199\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 21.1837 - mae: 3.2309 - val_loss: 20.8798 - val_mae: 3.3877\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 20.7793 - mae: 3.1864 - val_loss: 20.4586 - val_mae: 3.3434\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 20.4140 - mae: 3.1525 - val_loss: 20.1275 - val_mae: 3.3134\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 20.0896 - mae: 3.1294 - val_loss: 19.9689 - val_mae: 3.2855\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 19.6149 - mae: 3.0954 - val_loss: 19.4384 - val_mae: 3.2318\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 19.2546 - mae: 3.0589 - val_loss: 19.1901 - val_mae: 3.1947\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 18.9532 - mae: 3.0312 - val_loss: 18.9037 - val_mae: 3.1622\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 18.6381 - mae: 3.0077 - val_loss: 18.7190 - val_mae: 3.1443\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 18.4145 - mae: 2.9964 - val_loss: 18.7104 - val_mae: 3.1295\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 18.0135 - mae: 2.9739 - val_loss: 18.4493 - val_mae: 3.0926\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.7549 - mae: 2.9510 - val_loss: 18.3683 - val_mae: 3.0719\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.4975 - mae: 2.9271 - val_loss: 18.1363 - val_mae: 3.0382\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.2634 - mae: 2.8960 - val_loss: 17.9055 - val_mae: 3.0180\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 17.0441 - mae: 2.8833 - val_loss: 17.9560 - val_mae: 3.0311\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.7540 - mae: 2.8660 - val_loss: 17.8402 - val_mae: 3.0142\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.5794 - mae: 2.8532 - val_loss: 17.7985 - val_mae: 3.0039\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.3795 - mae: 2.8337 - val_loss: 17.6222 - val_mae: 2.9962\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 16.1483 - mae: 2.8024 - val_loss: 17.2881 - val_mae: 2.9576\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.0448 - mae: 2.7764 - val_loss: 17.0817 - val_mae: 2.9329\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.9165 - mae: 2.7731 - val_loss: 17.3584 - val_mae: 2.9956\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.6277 - mae: 2.7685 - val_loss: 17.0521 - val_mae: 2.9605\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 15.3581 - mae: 2.7403 - val_loss: 17.1657 - val_mae: 2.9668\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.2903 - mae: 2.7347 - val_loss: 16.8829 - val_mae: 2.9419\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 15.0255 - mae: 2.7230 - val_loss: 17.1362 - val_mae: 2.9687\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.9325 - mae: 2.7218 - val_loss: 17.0637 - val_mae: 2.9483\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.7510 - mae: 2.6998 - val_loss: 16.8122 - val_mae: 2.9458\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.6180 - mae: 2.6869 - val_loss: 16.7603 - val_mae: 2.9316\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.4254 - mae: 2.6533 - val_loss: 16.5164 - val_mae: 2.8975\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.2944 - mae: 2.6268 - val_loss: 16.3532 - val_mae: 2.8966\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.1825 - mae: 2.6270 - val_loss: 16.7395 - val_mae: 2.9268\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.0213 - mae: 2.6182 - val_loss: 16.6337 - val_mae: 2.8998\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.9249 - mae: 2.6015 - val_loss: 16.4648 - val_mae: 2.8779\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.7858 - mae: 2.5877 - val_loss: 16.2891 - val_mae: 2.8855\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.7996 - mae: 2.6124 - val_loss: 16.4764 - val_mae: 2.9115\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.5621 - mae: 2.5838 - val_loss: 16.1895 - val_mae: 2.8675\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.4111 - mae: 2.5466 - val_loss: 15.9053 - val_mae: 2.8368\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.3174 - mae: 2.5338 - val_loss: 15.9932 - val_mae: 2.8342\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.2759 - mae: 2.5354 - val_loss: 16.1919 - val_mae: 2.8484\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.1280 - mae: 2.5153 - val_loss: 15.9710 - val_mae: 2.8297\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.0219 - mae: 2.4997 - val_loss: 15.9700 - val_mae: 2.8144\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.9986 - mae: 2.4950 - val_loss: 16.0487 - val_mae: 2.8186\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.9240 - mae: 2.5079 - val_loss: 15.9792 - val_mae: 2.8450\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.8152 - mae: 2.4908 - val_loss: 15.9536 - val_mae: 2.8310\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.5883 - mae: 2.4827 - val_loss: 16.2063 - val_mae: 2.8422\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.6027 - mae: 2.4903 - val_loss: 16.0238 - val_mae: 2.8270\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.5578 - mae: 2.5031 - val_loss: 16.1925 - val_mae: 2.8454\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.3898 - mae: 2.4883 - val_loss: 15.8275 - val_mae: 2.8286\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.3471 - mae: 2.4619 - val_loss: 15.4089 - val_mae: 2.7851\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.3814 - mae: 2.4664 - val_loss: 15.4175 - val_mae: 2.8113\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.1551 - mae: 2.4436 - val_loss: 15.8235 - val_mae: 2.8028\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.0745 - mae: 2.4449 - val_loss: 15.7574 - val_mae: 2.8005\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.9961 - mae: 2.4438 - val_loss: 15.5623 - val_mae: 2.8061\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.9185 - mae: 2.4370 - val_loss: 15.3126 - val_mae: 2.7882\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.9336 - mae: 2.4360 - val_loss: 15.5078 - val_mae: 2.7960\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.7769 - mae: 2.4079 - val_loss: 15.1287 - val_mae: 2.7474\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.7244 - mae: 2.4049 - val_loss: 15.0664 - val_mae: 2.7788\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.6608 - mae: 2.4116 - val_loss: 15.2448 - val_mae: 2.8028\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.5644 - mae: 2.3913 - val_loss: 15.0681 - val_mae: 2.7574\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.4508 - mae: 2.3822 - val_loss: 15.3291 - val_mae: 2.7699\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.4110 - mae: 2.3884 - val_loss: 15.2646 - val_mae: 2.7663\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.3227 - mae: 2.3793 - val_loss: 15.1012 - val_mae: 2.7659\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.4104 - mae: 2.3737 - val_loss: 14.8057 - val_mae: 2.7364\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.1635 - mae: 2.3740 - val_loss: 15.4959 - val_mae: 2.8052\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.2481 - mae: 2.4014 - val_loss: 15.2441 - val_mae: 2.7867\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.0866 - mae: 2.3613 - val_loss: 14.7177 - val_mae: 2.7286\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.0102 - mae: 2.3413 - val_loss: 14.6524 - val_mae: 2.7377\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.9740 - mae: 2.3426 - val_loss: 14.5518 - val_mae: 2.7536\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.8880 - mae: 2.3359 - val_loss: 14.6533 - val_mae: 2.7236\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.8033 - mae: 2.3268 - val_loss: 14.4488 - val_mae: 2.7097\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.7605 - mae: 2.3288 - val_loss: 14.5989 - val_mae: 2.7263\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.6902 - mae: 2.3192 - val_loss: 14.4325 - val_mae: 2.7203\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.6122 - mae: 2.3065 - val_loss: 14.4144 - val_mae: 2.7068\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.5982 - mae: 2.2991 - val_loss: 14.4156 - val_mae: 2.6941\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.5542 - mae: 2.2979 - val_loss: 14.3278 - val_mae: 2.6986\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.4818 - mae: 2.2946 - val_loss: 14.3768 - val_mae: 2.7008\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4062 - mae: 2.2861 - val_loss: 14.2754 - val_mae: 2.7072\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.4288 - mae: 2.2849 - val_loss: 14.2900 - val_mae: 2.6762\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.3374 - mae: 2.2657 - val_loss: 14.0721 - val_mae: 2.7034\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.3101 - mae: 2.2909 - val_loss: 14.6732 - val_mae: 2.7449\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.2441 - mae: 2.2854 - val_loss: 14.1579 - val_mae: 2.6918\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.1159 - mae: 2.2563 - val_loss: 13.9703 - val_mae: 2.6797\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.1143 - mae: 2.2575 - val_loss: 14.1785 - val_mae: 2.7001\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.0500 - mae: 2.2405 - val_loss: 13.9841 - val_mae: 2.6604\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.0239 - mae: 2.2548 - val_loss: 14.1610 - val_mae: 2.7072\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.9072 - mae: 2.2422 - val_loss: 13.7507 - val_mae: 2.6552\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.9350 - mae: 2.2321 - val_loss: 13.8424 - val_mae: 2.6713\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8632 - mae: 2.2196 - val_loss: 13.5976 - val_mae: 2.6381\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.7865 - mae: 2.2135 - val_loss: 13.6710 - val_mae: 2.6643\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6879 - mae: 2.2264 - val_loss: 14.0338 - val_mae: 2.6871\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8330 - mae: 2.2396 - val_loss: 14.0934 - val_mae: 2.6824\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.7322 - mae: 2.2299 - val_loss: 13.8930 - val_mae: 2.7076\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.5965 - mae: 2.2172 - val_loss: 14.0380 - val_mae: 2.6954\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.5728 - mae: 2.2102 - val_loss: 13.7717 - val_mae: 2.6648\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.5353 - mae: 2.1943 - val_loss: 13.5077 - val_mae: 2.6532\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.4359 - mae: 2.1906 - val_loss: 13.6987 - val_mae: 2.6702\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.5545 - mae: 2.2119 - val_loss: 13.8252 - val_mae: 2.6486\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4027 - mae: 2.1675 - val_loss: 13.3039 - val_mae: 2.6362\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.3110 - mae: 2.1728 - val_loss: 13.6570 - val_mae: 2.6780\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.3632 - mae: 2.1810 - val_loss: 13.7172 - val_mae: 2.6525\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.1487 - mae: 2.1556 - val_loss: 13.3227 - val_mae: 2.6337\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.2020 - mae: 2.1463 - val_loss: 13.3029 - val_mae: 2.6409\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.0922 - mae: 2.1372 - val_loss: 13.4341 - val_mae: 2.6294\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.0652 - mae: 2.1453 - val_loss: 13.6989 - val_mae: 2.6669\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.0560 - mae: 2.1559 - val_loss: 13.5851 - val_mae: 2.6699\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.0306 - mae: 2.1344 - val_loss: 13.4601 - val_mae: 2.6245\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.9251 - mae: 2.1311 - val_loss: 13.8678 - val_mae: 2.6739\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9531 - mae: 2.1470 - val_loss: 13.6620 - val_mae: 2.6743\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.8156 - mae: 2.1139 - val_loss: 13.1151 - val_mae: 2.6115\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8716 - mae: 2.1118 - val_loss: 13.1848 - val_mae: 2.6180\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8289 - mae: 2.1149 - val_loss: 13.1091 - val_mae: 2.6425\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7610 - mae: 2.1193 - val_loss: 13.2323 - val_mae: 2.6328\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.6835 - mae: 2.1003 - val_loss: 13.1992 - val_mae: 2.6025\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7205 - mae: 2.0899 - val_loss: 13.0350 - val_mae: 2.6001\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7556 - mae: 2.1285 - val_loss: 13.8957 - val_mae: 2.7076\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6349 - mae: 2.1244 - val_loss: 13.1890 - val_mae: 2.6597\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.4978 - mae: 2.0885 - val_loss: 13.0531 - val_mae: 2.5928\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6143 - mae: 2.0747 - val_loss: 12.9418 - val_mae: 2.5847\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4649 - mae: 2.0773 - val_loss: 13.1596 - val_mae: 2.6476\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5159 - mae: 2.0979 - val_loss: 13.1974 - val_mae: 2.6209\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.4263 - mae: 2.0645 - val_loss: 12.7195 - val_mae: 2.5768\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3107 - mae: 2.0499 - val_loss: 13.0205 - val_mae: 2.6177\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3022 - mae: 2.0664 - val_loss: 13.0451 - val_mae: 2.6224\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2813 - mae: 2.0513 - val_loss: 13.0209 - val_mae: 2.5810\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3088 - mae: 2.0738 - val_loss: 13.3835 - val_mae: 2.6715\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.1916 - mae: 2.0595 - val_loss: 12.9338 - val_mae: 2.5996\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.1186 - mae: 2.0358 - val_loss: 12.8045 - val_mae: 2.5946\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.0643 - mae: 2.0252 - val_loss: 13.0052 - val_mae: 2.5928\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.0196 - mae: 2.0253 - val_loss: 12.6627 - val_mae: 2.5610\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.0199 - mae: 2.0145 - val_loss: 12.6528 - val_mae: 2.5898\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.0259 - mae: 2.0225 - val_loss: 12.9037 - val_mae: 2.6026\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9059 - mae: 2.0187 - val_loss: 12.7201 - val_mae: 2.5895\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8407 - mae: 2.0018 - val_loss: 12.7298 - val_mae: 2.5779\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.8526 - mae: 2.0062 - val_loss: 12.7978 - val_mae: 2.5992\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.8490 - mae: 2.0054 - val_loss: 12.7143 - val_mae: 2.5701\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.7907 - mae: 1.9991 - val_loss: 12.6606 - val_mae: 2.5758\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.7390 - mae: 1.9874 - val_loss: 12.4377 - val_mae: 2.5571\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7319 - mae: 1.9988 - val_loss: 12.6994 - val_mae: 2.5832\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6544 - mae: 1.9825 - val_loss: 12.6551 - val_mae: 2.5635\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.6196 - mae: 1.9731 - val_loss: 12.5613 - val_mae: 2.5666\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.6247 - mae: 1.9782 - val_loss: 12.6966 - val_mae: 2.5973\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6595 - mae: 1.9803 - val_loss: 12.4004 - val_mae: 2.5574\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.5249 - mae: 1.9708 - val_loss: 12.8687 - val_mae: 2.5699\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.4842 - mae: 1.9685 - val_loss: 12.6004 - val_mae: 2.5486\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.4450 - mae: 1.9525 - val_loss: 12.3415 - val_mae: 2.5688\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4924 - mae: 1.9637 - val_loss: 12.6440 - val_mae: 2.5709\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3773 - mae: 1.9572 - val_loss: 12.4998 - val_mae: 2.5594\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.3700 - mae: 1.9452 - val_loss: 12.3912 - val_mae: 2.5673\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.3053 - mae: 1.9362 - val_loss: 12.5450 - val_mae: 2.5617\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.2885 - mae: 1.9485 - val_loss: 12.7164 - val_mae: 2.5658\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2298 - mae: 1.9331 - val_loss: 12.3242 - val_mae: 2.5543\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.1880 - mae: 1.9199 - val_loss: 12.3688 - val_mae: 2.5370\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1495 - mae: 1.9240 - val_loss: 12.6009 - val_mae: 2.5589\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.1556 - mae: 1.9284 - val_loss: 12.7452 - val_mae: 2.5696\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0971 - mae: 1.9201 - val_loss: 12.3301 - val_mae: 2.5229\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0706 - mae: 1.9090 - val_loss: 12.1902 - val_mae: 2.5303\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1278 - mae: 1.9334 - val_loss: 12.8329 - val_mae: 2.5964\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9909 - mae: 1.9123 - val_loss: 12.3717 - val_mae: 2.5322\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.9751 - mae: 1.8934 - val_loss: 12.2073 - val_mae: 2.5316\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.9846 - mae: 1.8919 - val_loss: 12.2894 - val_mae: 2.5269\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.9157 - mae: 1.8960 - val_loss: 12.5883 - val_mae: 2.5488\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.8802 - mae: 1.8976 - val_loss: 12.3792 - val_mae: 2.5479\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.8686 - mae: 1.8958 - val_loss: 12.4567 - val_mae: 2.5778\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8653 - mae: 1.8938 - val_loss: 12.6130 - val_mae: 2.5436\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8740 - mae: 1.9019 - val_loss: 12.5004 - val_mae: 2.5400\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7109 - mae: 1.8633 - val_loss: 11.9089 - val_mae: 2.5162\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8494 - mae: 1.8806 - val_loss: 12.2165 - val_mae: 2.5165\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.6946 - mae: 1.8728 - val_loss: 12.3036 - val_mae: 2.5317\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.6790 - mae: 1.8629 - val_loss: 12.0601 - val_mae: 2.5128\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5921 - mae: 1.8583 - val_loss: 12.4069 - val_mae: 2.5146\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6537 - mae: 1.8824 - val_loss: 12.6613 - val_mae: 2.5674\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5630 - mae: 1.8583 - val_loss: 12.2051 - val_mae: 2.5164\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5340 - mae: 1.8476 - val_loss: 12.1521 - val_mae: 2.5087\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4669 - mae: 1.8387 - val_loss: 12.1269 - val_mae: 2.5300\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5788 - mae: 1.8742 - val_loss: 12.2926 - val_mae: 2.5560\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.4855 - mae: 1.8456 - val_loss: 11.9831 - val_mae: 2.4845\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4486 - mae: 1.8407 - val_loss: 12.1509 - val_mae: 2.5178\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.6117 - mae: 1.8810 - val_loss: 12.5691 - val_mae: 2.5766\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4802 - mae: 1.8404 - val_loss: 11.9492 - val_mae: 2.4723\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4161 - mae: 1.8323 - val_loss: 12.1373 - val_mae: 2.5214\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.3349 - mae: 1.8257 - val_loss: 12.0231 - val_mae: 2.5144\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.3069 - mae: 1.8111 - val_loss: 11.8370 - val_mae: 2.4932\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2642 - mae: 1.8037 - val_loss: 11.9768 - val_mae: 2.4931\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2866 - mae: 1.8187 - val_loss: 12.3444 - val_mae: 2.5450\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2106 - mae: 1.8072 - val_loss: 11.9051 - val_mae: 2.4686\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.2501 - mae: 1.8033 - val_loss: 11.9411 - val_mae: 2.4836\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.1637 - mae: 1.7954 - val_loss: 11.9976 - val_mae: 2.5165\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.1267 - mae: 1.7992 - val_loss: 12.0011 - val_mae: 2.4749\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1389 - mae: 1.7970 - val_loss: 11.8685 - val_mae: 2.4755\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0549 - mae: 1.7814 - val_loss: 11.9394 - val_mae: 2.5108\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0710 - mae: 1.7873 - val_loss: 12.0984 - val_mae: 2.5016\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.0195 - mae: 1.7812 - val_loss: 11.7413 - val_mae: 2.4599\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0068 - mae: 1.7728 - val_loss: 11.8547 - val_mae: 2.4749\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9807 - mae: 1.7676 - val_loss: 11.7975 - val_mae: 2.4715\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.9700 - mae: 1.7585 - val_loss: 11.8180 - val_mae: 2.4684\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9355 - mae: 1.7640 - val_loss: 12.1322 - val_mae: 2.5139\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9293 - mae: 1.7675 - val_loss: 11.6164 - val_mae: 2.4484\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.9196 - mae: 1.7499 - val_loss: 11.5324 - val_mae: 2.4547\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.0619 - mae: 1.7783 - val_loss: 12.2871 - val_mae: 2.5270\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8385 - mae: 1.7410 - val_loss: 11.4500 - val_mae: 2.4490\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8624 - mae: 1.7476 - val_loss: 11.6179 - val_mae: 2.4540\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8439 - mae: 1.7573 - val_loss: 11.9543 - val_mae: 2.5010\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8382 - mae: 1.7429 - val_loss: 11.5187 - val_mae: 2.4613\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7251 - mae: 1.7375 - val_loss: 11.9416 - val_mae: 2.4696\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7148 - mae: 1.7373 - val_loss: 11.8707 - val_mae: 2.4727\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7301 - mae: 1.7357 - val_loss: 11.6830 - val_mae: 2.4550\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6912 - mae: 1.7210 - val_loss: 11.4891 - val_mae: 2.4611\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6317 - mae: 1.7142 - val_loss: 11.7291 - val_mae: 2.4584\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6351 - mae: 1.7142 - val_loss: 11.7953 - val_mae: 2.4659\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6214 - mae: 1.7170 - val_loss: 11.7511 - val_mae: 2.4515\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6928 - mae: 1.7437 - val_loss: 12.0175 - val_mae: 2.5031\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5319 - mae: 1.7027 - val_loss: 11.7698 - val_mae: 2.4411\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6223 - mae: 1.7113 - val_loss: 11.5662 - val_mae: 2.4427\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5410 - mae: 1.6896 - val_loss: 11.5204 - val_mae: 2.4723\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5539 - mae: 1.6974 - val_loss: 11.8663 - val_mae: 2.4637\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4620 - mae: 1.6823 - val_loss: 11.5450 - val_mae: 2.4459\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4842 - mae: 1.6842 - val_loss: 11.6432 - val_mae: 2.4527\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4657 - mae: 1.6869 - val_loss: 11.5666 - val_mae: 2.4517\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4688 - mae: 1.6874 - val_loss: 11.5744 - val_mae: 2.4495\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5162 - mae: 1.6811 - val_loss: 11.2862 - val_mae: 2.4344\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4252 - mae: 1.6620 - val_loss: 11.8544 - val_mae: 2.4642\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3755 - mae: 1.6665 - val_loss: 11.3828 - val_mae: 2.4345\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3787 - mae: 1.6647 - val_loss: 11.5818 - val_mae: 2.4485\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3879 - mae: 1.6954 - val_loss: 11.6830 - val_mae: 2.4773\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3276 - mae: 1.6612 - val_loss: 11.3166 - val_mae: 2.4216\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2464 - mae: 1.6437 - val_loss: 11.4316 - val_mae: 2.4625\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2675 - mae: 1.6717 - val_loss: 11.6247 - val_mae: 2.4657\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3510 - mae: 1.6631 - val_loss: 11.1489 - val_mae: 2.4277\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2282 - mae: 1.6476 - val_loss: 11.3705 - val_mae: 2.4452\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.1901 - mae: 1.6515 - val_loss: 11.5417 - val_mae: 2.4504\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1738 - mae: 1.6495 - val_loss: 11.5307 - val_mae: 2.4604\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.1425 - mae: 1.6555 - val_loss: 11.5055 - val_mae: 2.4607\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1750 - mae: 1.6486 - val_loss: 11.6189 - val_mae: 2.4388\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1499 - mae: 1.6443 - val_loss: 11.2420 - val_mae: 2.4330\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0543 - mae: 1.6170 - val_loss: 11.4074 - val_mae: 2.4204\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0739 - mae: 1.6125 - val_loss: 11.3182 - val_mae: 2.4378\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0080 - mae: 1.6127 - val_loss: 11.7013 - val_mae: 2.4667\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1005 - mae: 1.6213 - val_loss: 11.3316 - val_mae: 2.4280\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0254 - mae: 1.6228 - val_loss: 11.4159 - val_mae: 2.4565\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9677 - mae: 1.6198 - val_loss: 11.2970 - val_mae: 2.4261\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9358 - mae: 1.5952 - val_loss: 11.4140 - val_mae: 2.4285\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.9627 - mae: 1.6153 - val_loss: 11.4898 - val_mae: 2.4511\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9840 - mae: 1.6339 - val_loss: 11.4224 - val_mae: 2.4361\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0192 - mae: 1.6150 - val_loss: 11.0465 - val_mae: 2.4201\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.8868 - mae: 1.5734 - val_loss: 11.4227 - val_mae: 2.4566\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8893 - mae: 1.6124 - val_loss: 11.6653 - val_mae: 2.4555\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9534 - mae: 1.6151 - val_loss: 11.5657 - val_mae: 2.4441\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9194 - mae: 1.6143 - val_loss: 11.3360 - val_mae: 2.4350\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7823 - mae: 1.5718 - val_loss: 11.1451 - val_mae: 2.4052\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8285 - mae: 1.5831 - val_loss: 11.4160 - val_mae: 2.4435\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7697 - mae: 1.5642 - val_loss: 11.1161 - val_mae: 2.4302\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8155 - mae: 1.5831 - val_loss: 11.4536 - val_mae: 2.4632\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8538 - mae: 1.5864 - val_loss: 11.1796 - val_mae: 2.4313\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8042 - mae: 1.5841 - val_loss: 11.1257 - val_mae: 2.4482\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.7435 - mae: 1.5642 - val_loss: 11.3607 - val_mae: 2.4297\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7163 - mae: 1.5630 - val_loss: 11.1715 - val_mae: 2.4301\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7527 - mae: 1.5802 - val_loss: 11.4964 - val_mae: 2.4545\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.6476 - mae: 1.5491 - val_loss: 11.3701 - val_mae: 2.4159\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6346 - mae: 1.5331 - val_loss: 11.1814 - val_mae: 2.4230\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.6742 - mae: 1.5610 - val_loss: 11.4005 - val_mae: 2.4641\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5941 - mae: 1.5394 - val_loss: 11.2024 - val_mae: 2.4187\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6511 - mae: 1.5424 - val_loss: 11.2329 - val_mae: 2.4415\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5476 - mae: 1.5224 - val_loss: 11.2332 - val_mae: 2.4105\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5796 - mae: 1.5364 - val_loss: 11.1522 - val_mae: 2.4382\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5655 - mae: 1.5315 - val_loss: 11.1661 - val_mae: 2.4083\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 10.6613 - mae: 2.2375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyPwsgfpvoEP"
      },
      "source": [
        "### K-Fold 결과 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AqnkWRrujps",
        "outputId": "20419bff-e484-4aad-ce13-9905f1cece26"
      },
      "source": [
        "print(f'전체 결과: {mae_list}')\n",
        "print(f'평균낸 결과를 최종 결과로 사용합니다: {np.mean(mae_list)}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 결과: [2.0720932483673096, 2.035085439682007, 2.23749041557312]\n",
            "평균낸 결과를 최종 결과로 사용합니다: 2.114889701207479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEblpM98vrWy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}